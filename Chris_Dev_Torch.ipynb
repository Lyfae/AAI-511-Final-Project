{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686f5bc2",
   "metadata": {},
   "source": [
    "___\n",
    "##### $Name:\\,\\color{blue}{Christopher\\,J.\\,Watson\\,,Nathan\\,Edwards\\,,Paul\\,Thai}$\n",
    "##### $School:\\,\\color{blue}{Marcos\\,School\\,of\\,Engineering,\\,University\\,of\\,San\\,Diego}$\n",
    "##### $Class:\\,\\color{blue}{AAI\\,511-\\,Neural\\,Networks\\,and\\,Learning}$\n",
    "##### $Assignment:\\,\\color{blue}{MSAAI\\,Final\\,Project}$\n",
    "##### $Date:\\,\\color{blue}{8/15/2023}$\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc343580",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f13274e2-c25d-4b74-8ebf-4c8c0c18b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "\n",
    "# File and Data Handling\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Data Visualization and Numerical Computing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# MIDI Processing\n",
    "import mido\n",
    "\n",
    "# Machine Learning and Deep Learning\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# Machine learning Metrics and Evaluations\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c13ef",
   "metadata": {},
   "source": [
    "### Classes\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2a17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def enum(self,y):\n",
    "        composers = [\"bach\", \"bartok\", \"byrd\", \"chopin\", \"handel\", \"hummel\", \"mendelssohn\",\"mozart\", \"schumann\"]\n",
    "        #print(y)\n",
    "        for i in range(len(composers)):\n",
    "            if composers[i] == y:\n",
    "                slot = i\n",
    "        out = [0] * 9\n",
    "        out[slot] = 1\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        label = self.enum(label)\n",
    "           \n",
    "        \n",
    "        sequence = torch.tensor(sequence)\n",
    "        label = torch.tensor(label)\n",
    "        sequence = sequence[None, :, :] \n",
    "        return sequence, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ffd187",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a13e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(a_dir):\n",
    "    dirs = []\n",
    "    files = []\n",
    "    for name in os.listdir(a_dir):\n",
    "        if os.path.isdir(os.path.join(a_dir, name)):\n",
    "            dirs.append(name)\n",
    "        else:\n",
    "            files.append(name)\n",
    "    return [dirs,files]\n",
    "\n",
    "def create_files_table(top_level, out_file):\n",
    "    temp_comps = []\n",
    "    temp_songs = []\n",
    "    temp_paths = []\n",
    "    \n",
    "    composer_names, songs = get_children(top_level)\n",
    "\n",
    "    for composer in composer_names:\n",
    "        temp_path = top_level + '/' + composer\n",
    "        temp, songs = get_children(temp_path)\n",
    "        for song in songs:\n",
    "            if song != '.DS_Store':\n",
    "                temp_comps.append(composer)\n",
    "                temp_paths.append(temp_path + '/' + song)\n",
    "                temp_songs.append(song.split(\".\")[0])\n",
    "\n",
    "    temp_dict = {'Composers': temp_comps, 'Songs': temp_songs, 'Paths': temp_paths}\n",
    "\n",
    "    table = pd.DataFrame.from_dict(temp_dict)\n",
    "\n",
    "    table.to_csv('./' + out_file + '.csv',index=False)\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n",
    "# Function to extract the notes played in a MIDI file with timestamps\n",
    "def extract_notes_with_meta(midi_filepath):\n",
    "    notes = {}\n",
    "    midi = mido.MidiFile(midi_filepath)\n",
    "    max_time = 0\n",
    "    time_counter = 0\n",
    "    for track in midi.tracks:\n",
    "        time_counter = 0\n",
    "        for msg in track:\n",
    "            time_counter += msg.time\n",
    "            max_time = max(max_time,time_counter)\n",
    "            if msg.type == 'note_on':\n",
    "                if msg.velocity != 0:  # Ensure it's a Note On event\n",
    "                    notes[msg.note] = notes.get(msg.note, []) + [(msg.velocity, time_counter, 1)]  # 1 represents Note On\n",
    "            elif msg.type == 'note_off':\n",
    "                notes[msg.note] = notes.get(msg.note, []) + [(msg.velocity,time_counter, 0)]  # 0 represents Note Off\n",
    "                \n",
    "    return notes, max_time\n",
    "\n",
    "\n",
    "def create_single_sequences(notes, start, tick_count, seq_count): \n",
    "    VEL = 0\n",
    "    TM = 1\n",
    "    ON = 2\n",
    "    \n",
    "    temp_keys = notes.keys()\n",
    "\n",
    "    seq =  [[0] * 128]* seq_count\n",
    "    seq = np.array(seq)\n",
    "\n",
    "    for x in temp_keys:\n",
    "        temp_note = np.array(notes[x])\n",
    "        time_store = 0\n",
    "        for i in range(start, seq_count+start):\n",
    "            temp_vel = 0\n",
    "            for t in range(time_store,temp_note[:,TM].size):\n",
    "                if (temp_note[t,TM]>tick_count*i):\n",
    "                    break\n",
    "                else:\n",
    "                    if temp_note[t,ON] == 1:\n",
    "                        if temp_note[t,VEL] > temp_vel:\n",
    "                            temp_vel = temp_note[t,VEL]\n",
    "                time_store = t\n",
    "            seq[i-start,x] = temp_vel\n",
    "    return seq\n",
    "\n",
    "def sequence_songs(df_songs, tick_count, seq_count, jiggle_on=False):\n",
    "    labels = []\n",
    "    sequences = []\n",
    "    \n",
    "    \n",
    "    shake_amount = 0\n",
    "    \n",
    "    if jiggle_on:\n",
    "        shake_amount = [0, int(seq_count/2), int(seq_count/4)]\n",
    "    \n",
    "    for j in shake_amount:\n",
    "        for song in df_songs.iterrows():\n",
    "            song = song[1]\n",
    "            notes, max_time = extract_notes_with_meta(song['Paths'])\n",
    "\n",
    "            for i in range(int((max_time-j)/(seq_count*tick_count))):\n",
    "                sequences.append(create_single_sequences(notes, i*seq_count+j, tick_count, seq_count))\n",
    "                labels.append(song['Composers'])\n",
    "                \n",
    "    return labels, sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d0145",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baba92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "devpath = './Composer_Dataset/NN_midi_files_extended/dev/'\n",
    "testpath = './Composer_Dataset/NN_midi_files_extended/test/'\n",
    "trainpath = './Composer_Dataset/NN_midi_files_extended/train/'\n",
    "\n",
    "dev_table = create_files_table(devpath, 'dev_table')\n",
    "test_table = create_files_table(testpath, 'test_table')\n",
    "train_table = create_files_table(trainpath, 'train_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38ea1d3-2dbd-4a8b-befc-2d2ec5edeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_file_path = './Composer_Dataset/NN_midi_files_extended/dev/bach/bach344.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d65289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, sequences = sequence_songs(train_table, 200, 128,jiggle_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0ddc86-088f-4496-bec5-4a18519e781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test, sequences_test = sequence_songs(test_table, 200, 128,jiggle_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3134245-faec-4661-8bb1-bd6be81963bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bach',\n",
       " 'bartok',\n",
       " 'byrd',\n",
       " 'chopin',\n",
       " 'handel',\n",
       " 'hummel',\n",
       " 'mendelssohn',\n",
       " 'mozart',\n",
       " 'schumann'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myset = set(labels_test)\n",
    "myset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346fe46-e169-42c0-984e-2df368b2ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_notes_with_meta('./Composer_Dataset/NN_midi_files_extended/test/byrd/byrd150.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3d0cc4d-b025-4a19-988f-efaf34735853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bach', 'bartok', 'byrd', 'chopin', 'handel', 'hummel',\n",
       "       'mendelssohn', 'mozart', 'schumann'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dsadasda\n",
    "train_table.Composers.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caac14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset for the dataloader\n",
    "dataset = Dataset(sequences, labels)\n",
    "dataset_test = Dataset(sequences_test, labels_test)\n",
    "\n",
    "# Creating data loader\n",
    "batch_size = 1\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d82b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a82b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df820bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Creation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfd7922c-c399-4931-b7f2-4b598b811bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "    \n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.LSTM = nn.LSTM(4, 200, 5, batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(800, 400)\n",
    "        self.fc2 = nn.Linear(400, 200)\n",
    "        self.fc3 = nn.Linear(200, 100)  \n",
    "        self.fc4 = nn.Linear(100, 9)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv4(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv5(x)))\n",
    "\n",
    "        x =  x[:,0,:,:]\n",
    "        h0 = torch.zeros(5, x.size(0), 200)\n",
    "        c0 = torch.zeros(5, x.size(0), 200)        \n",
    "        x, _ = self.LSTM(x, (h0, c0)) \n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        # return nn.functional.sigmoid(x)\n",
    "        return self.soft(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88fe84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = CNN() \n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adagrad(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c7c99",
   "metadata": {},
   "source": [
    "### Training\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b89ff74-bb94-4e2a-8575-ec5c6e4c56fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Test(dataloader, best_model):\n",
    "    # Evaluating the model\n",
    "    model.eval()\n",
    "\n",
    "    real = []\n",
    "    pred = []\n",
    "    counter = 0\n",
    "    # Disable gradient computation to save memory\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            outputs = outputs.tolist()\n",
    "            labels = labels.tolist()\n",
    "\n",
    "            pred_labal = outputs[0].index(max(outputs[0]))\n",
    "\n",
    "            real_label = labels[0].index(max(labels[0]))\n",
    "\n",
    "            real.append(real_label)\n",
    "            pred.append(pred_labal)\n",
    "            \n",
    "    \n",
    "    score = f1_score(pred, real, average = \"weighted\")\n",
    "    \n",
    "    if score > best_model:\n",
    "        best_model = score\n",
    "        torch.save(model.state_dict(), 'model_something.pt')\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75eec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 180\n",
    "prev = time.time()\n",
    "best_model = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in data_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(torch.float)\n",
    "        labels = labels.to(torch.float)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    best_model = Test(test_loader, best_model)\n",
    "    now = time.time()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} Time Taken: {now-prev}s F1-Score: {best_model}\")\n",
    "    prev = now\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc2f9a",
   "metadata": {},
   "source": [
    "### Evaulation and Results\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08950bb1-07c6-47f0-b135-498ab0178840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "\n",
    "prediction_list = list()\n",
    "labels_list = list()\n",
    "\n",
    "real = []\n",
    "pred = []\n",
    "counter = 0\n",
    "# Disable gradient computation to save memory\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        #print(outputs)\n",
    "        \n",
    "        outputs = outputs.tolist()\n",
    "        labels = labels.tolist()\n",
    "        \n",
    "        pred_labal = outputs[0].index(max(outputs[0]))\n",
    "        \n",
    "\n",
    "        #print(pred_labal)\n",
    "        \n",
    "        #print(labels)\n",
    "        \n",
    "        real_label = labels[0].index(max(labels[0]))\n",
    "        \n",
    "        real.append(real_label)\n",
    "        pred.append(pred_labal)\n",
    "\n",
    "\n",
    "        \n",
    "print(classification_report(real, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a18feb-57ea-4c53-a7e2-fdfd576ad4ad",
   "metadata": {},
   "source": [
    "pred = []\n",
    "\n",
    "for inputs, labels in data_loader:\n",
    "    inputs = inputs.to(torch.float)\n",
    "    labels = labels.to(torch.float)\n",
    "    \n",
    "\n",
    "    pred.append(model(inputs).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
