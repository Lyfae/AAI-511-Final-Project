{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686f5bc2",
   "metadata": {},
   "source": [
    "___\n",
    "##### $Name:\\,\\color{blue}{Christopher\\,J.\\,Watson\\,,Nathan\\,Edwards\\,,Paul\\,Thai}$\n",
    "##### $School:\\,\\color{blue}{Marcos\\,School\\,of\\,Engineering,\\,University\\,of\\,San\\,Diego}$\n",
    "##### $Class:\\,\\color{blue}{AAI\\,511-\\,Neural\\,Networks\\,and\\,Learning}$\n",
    "##### $Assignment:\\,\\color{blue}{MSAAI\\,Final\\,Project}$\n",
    "##### $Date:\\,\\color{blue}{8/15/2023}$\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc343580",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13274e2-c25d-4b74-8ebf-4c8c0c18b7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n",
      "GPU Name:  NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "# Libraries \n",
    "\n",
    "# File and Data Handling\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Data Visualization and Numerical Computing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# MIDI Processing\n",
    "import mido\n",
    "\n",
    "# Machine Learning and Deep Learning\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# Machine learning Metrics and Evaluations\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print('GPU Available: ', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU Name: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    device = torch.device(\"cuda:\" + str(torch.cuda.current_device())) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c13ef",
   "metadata": {},
   "source": [
    "### Classes\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2a17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def enum(self,y):\n",
    "        composers = [\"bach\", \"bartok\", \"byrd\", \"chopin\", \"handel\", \"hummel\", \"mendelssohn\",\"mozart\", \"schumann\"]\n",
    "        #print(y)\n",
    "        for i in range(len(composers)):\n",
    "            if composers[i] == y:\n",
    "                slot = i\n",
    "        out = [0] * 9\n",
    "        out[slot] = 1\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        label = self.enum(label)\n",
    "           \n",
    "        \n",
    "        sequence = torch.tensor(sequence)\n",
    "        label = torch.tensor(label)\n",
    "        if torch.cuda.is_available():\n",
    "            label = label.to(device)\n",
    "            #print('GPU Tensor Enabled(Labels):', label.is_cuda)\n",
    "            sequence = sequence.to(device)\n",
    "            #print('GPU Tensor Enabled(Sequences):', sequence.is_cuda)\n",
    "        sequence = sequence[None, :, :] \n",
    "        return sequence, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ffd187",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a13e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(a_dir):\n",
    "    dirs = []\n",
    "    files = []\n",
    "    for name in os.listdir(a_dir):\n",
    "        if os.path.isdir(os.path.join(a_dir, name)):\n",
    "            dirs.append(name)\n",
    "        else:\n",
    "            files.append(name)\n",
    "    return [dirs,files]\n",
    "\n",
    "def create_files_table(top_level, out_file):\n",
    "    temp_comps = []\n",
    "    temp_songs = []\n",
    "    temp_paths = []\n",
    "    \n",
    "    composer_names, songs = get_children(top_level)\n",
    "\n",
    "    for composer in composer_names:\n",
    "        temp_path = top_level + '/' + composer\n",
    "        temp, songs = get_children(temp_path)\n",
    "        for song in songs:\n",
    "            if song != '.DS_Store':\n",
    "                temp_comps.append(composer)\n",
    "                temp_paths.append(temp_path + '/' + song)\n",
    "                temp_songs.append(song.split(\".\")[0])\n",
    "\n",
    "    temp_dict = {'Composers': temp_comps, 'Songs': temp_songs, 'Paths': temp_paths}\n",
    "\n",
    "    table = pd.DataFrame.from_dict(temp_dict)\n",
    "\n",
    "    table.to_csv('./' + out_file + '.csv',index=False)\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n",
    "# Function to extract the notes played in a MIDI file with timestamps\n",
    "def extract_notes_with_meta(midi_filepath):\n",
    "    notes = {}\n",
    "    midi = mido.MidiFile(midi_filepath)\n",
    "    max_time = 0\n",
    "    time_counter = 0\n",
    "    for track in midi.tracks:\n",
    "        time_counter = 0\n",
    "        for msg in track:\n",
    "            time_counter += msg.time\n",
    "            max_time = max(max_time,time_counter)\n",
    "            if msg.type == 'note_on':\n",
    "                if msg.velocity != 0:  # Ensure it's a Note On event\n",
    "                    notes[msg.note] = notes.get(msg.note, []) + [(msg.velocity, time_counter, 1)]  # 1 represents Note On\n",
    "            elif msg.type == 'note_off':\n",
    "                notes[msg.note] = notes.get(msg.note, []) + [(msg.velocity,time_counter, 0)]  # 0 represents Note Off\n",
    "                \n",
    "    return notes, max_time\n",
    "\n",
    "\n",
    "def create_single_sequences(notes, start, tick_count, seq_count): \n",
    "    VEL = 0\n",
    "    TM = 1\n",
    "    ON = 2\n",
    "    \n",
    "    temp_keys = notes.keys()\n",
    "\n",
    "    seq =  [[0] * 128]* seq_count\n",
    "    seq = np.array(seq)\n",
    "\n",
    "    for x in temp_keys:\n",
    "        temp_note = np.array(notes[x])\n",
    "        time_store = 0\n",
    "        for i in range(start, seq_count+start):\n",
    "            temp_vel = 0\n",
    "            for t in range(time_store,temp_note[:,TM].size):\n",
    "                if (temp_note[t,TM]>tick_count*i):\n",
    "                    break\n",
    "                else:\n",
    "                    if temp_note[t,ON] == 1:\n",
    "                        if temp_note[t,VEL] > temp_vel:\n",
    "                            temp_vel = temp_note[t,VEL]\n",
    "                time_store = t\n",
    "            seq[i-start,x] = temp_vel\n",
    "    return seq\n",
    "\n",
    "def sequence_songs(df_songs, tick_count, seq_count, jiggle_on=False):\n",
    "    labels = []\n",
    "    sequences = []\n",
    "    \n",
    "    \n",
    "    shake_amount = [0]\n",
    "    #num_jiggle = 3\n",
    "    \n",
    "    if jiggle_on:\n",
    "       #for i in range(1,num_jiggle):\n",
    "        #shake_amount.append(int(seq_count/num_jiggle)*i)\n",
    "        #shake_amount = [0, seq_count/4, seq_count/2]\n",
    "        shake_amount = [0, int(seq_count/2)]\n",
    "    \n",
    "    for j in shake_amount:\n",
    "        for song in df_songs.iterrows():\n",
    "            song = song[1]\n",
    "            notes, max_time = extract_notes_with_meta(song['Paths'])\n",
    "\n",
    "            for i in range(int((max_time-j)/(seq_count*tick_count))):\n",
    "                sequences.append(create_single_sequences(notes, i*seq_count+j, tick_count, seq_count))\n",
    "                labels.append(song['Composers'])\n",
    "                \n",
    "    return labels, sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d0145",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baba92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "devpath = './Composer_Dataset/NN_midi_files_extended/dev/'\n",
    "testpath = './Composer_Dataset/NN_midi_files_extended/test/'\n",
    "trainpath = './Composer_Dataset/NN_midi_files_extended/train/'\n",
    "\n",
    "dev_table = create_files_table(devpath, 'dev_table')\n",
    "test_table = create_files_table(testpath, 'test_table')\n",
    "train_table = create_files_table(trainpath, 'train_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38ea1d3-2dbd-4a8b-befc-2d2ec5edeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_file_path = './Composer_Dataset/NN_midi_files_extended/dev/bach/bach344.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d65289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1labels, sequences = sequence_songs(train_table, 200, 128,jiggle_on=True)\n",
    "labels, sequences = sequence_songs(train_table, 180, 128,jiggle_on=True)\n",
    "#2labels, sequences = sequence_songs(train_table,  128, 128,jiggle_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0ddc86-088f-4496-bec5-4a18519e781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1labels_test, sequences_test = sequence_songs(test_table, 200, 128,jiggle_on=True)\n",
    "labels_test, sequences_test = sequence_songs(test_table, 180, 128,jiggle_on=True)\n",
    "#2labels_test, sequences_test = sequence_songs(test_table, 128, 128,jiggle_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3134245-faec-4661-8bb1-bd6be81963bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bach',\n",
       " 'bartok',\n",
       " 'byrd',\n",
       " 'chopin',\n",
       " 'handel',\n",
       " 'hummel',\n",
       " 'mendelssohn',\n",
       " 'mozart',\n",
       " 'schumann'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myset = set(labels_test)\n",
    "myset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2346fe46-e169-42c0-984e-2df368b2ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_notes_with_meta('./Composer_Dataset/NN_midi_files_extended/test/byrd/byrd150.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3d0cc4d-b025-4a19-988f-efaf34735853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bach', 'bartok', 'byrd', 'chopin', 'handel', 'hummel',\n",
       "       'mendelssohn', 'mozart', 'schumann'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dsadasda\n",
    "train_table.Composers.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caac14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset for the dataloader\n",
    "dataset = Dataset(sequences, labels)\n",
    "dataset_test = Dataset(sequences_test, labels_test)\n",
    "\n",
    "# Creating data loader\n",
    "batch_size = 1\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d82b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a82b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df820bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Creation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfd7922c-c399-4931-b7f2-4b598b811bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=2, padding=1)\n",
    "    \n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.LSTM = nn.LSTM(8, 300, 7, batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(2400, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 600)\n",
    "        self.fc3 = nn.Linear(600, 100)\n",
    "        self.fc4 = nn.Linear(100, 9)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv4(x)))\n",
    "\n",
    "        x =  x[:,0,:,:]\n",
    "        h0 = torch.zeros(7, x.size(0), 300)\n",
    "        c0 = torch.zeros(7, x.size(0), 300)     \n",
    "        if torch.cuda.is_available():\n",
    "            h0 = h0.to(device)\n",
    "            #print('GPU Tensor Enabled(labels):', labels.is_cuda)\n",
    "            c0 = c0.to(device)\n",
    "            #print('GPU Tensor Enabled(inputs):', inputs.is_cuda)\n",
    "        x, _ = self.LSTM(x, (h0, c0)) \n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        # return nn.functional.sigmoid(x)\n",
    "        return self.soft(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9374daab-2a1b-46d0-a166-575e60220c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = CNN() \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adagrad(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9deab72f-014a-430f-af2e-26b33e47fb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model-1_something-Best663.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c7c99",
   "metadata": {},
   "source": [
    "### Training\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31834753-2b6a-4307-b02e-b312ff6425a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Test(dataloader, best_model):\n",
    "    # Evaluating the model\n",
    "    model.eval()\n",
    "\n",
    "    real = []\n",
    "    pred = []\n",
    "    counter = 0\n",
    "    # Disable gradient computation to save memory\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            outputs = outputs.tolist()\n",
    "            labels = labels.tolist()\n",
    "\n",
    "            pred_labal = outputs[0].index(max(outputs[0]))\n",
    "\n",
    "            real_label = labels[0].index(max(labels[0]))\n",
    "\n",
    "            real.append(real_label)\n",
    "            pred.append(pred_labal)\n",
    "            \n",
    "    \n",
    "    score = f1_score(pred, real, average = \"weighted\")\n",
    "    \n",
    "    if score > best_model:\n",
    "        print(classification_report(real, pred))\n",
    "        best_model = score\n",
    "        torch.save(model.state_dict(), 'model_something.pt')\n",
    "    \n",
    "    return score, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "825b4f23-3f94-489f-ad5d-4bd7ca43fbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = 0.6647619806264979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75eec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/180] Loss: 0.0719 Time Taken: 54.92335891723633s F1-Score: 0.6396683492164658 Best-Score: 0.6634079019432532\n",
      "Epoch [2/180] Loss: 0.0553 Time Taken: 51.25590801239014s F1-Score: 0.6251552859786932 Best-Score: 0.6634079019432532\n",
      "Epoch [3/180] Loss: 0.0520 Time Taken: 49.98500871658325s F1-Score: 0.584482275050559 Best-Score: 0.6634079019432532\n",
      "Epoch [4/180] Loss: 0.0494 Time Taken: 51.184887409210205s F1-Score: 0.6156917674002392 Best-Score: 0.6634079019432532\n",
      "Epoch [5/180] Loss: 0.0477 Time Taken: 52.554221391677856s F1-Score: 0.6121654899335685 Best-Score: 0.6634079019432532\n",
      "Epoch [6/180] Loss: 0.0463 Time Taken: 52.553739070892334s F1-Score: 0.6119073556733458 Best-Score: 0.6634079019432532\n",
      "Epoch [7/180] Loss: 0.0455 Time Taken: 57.73086190223694s F1-Score: 0.5997079689593077 Best-Score: 0.6634079019432532\n",
      "Epoch [8/180] Loss: 0.0445 Time Taken: 55.74141883850098s F1-Score: 0.5825279011435235 Best-Score: 0.6634079019432532\n",
      "Epoch [9/180] Loss: 0.0438 Time Taken: 53.606606006622314s F1-Score: 0.5832977067450233 Best-Score: 0.6634079019432532\n",
      "Epoch [10/180] Loss: 0.0434 Time Taken: 52.69770622253418s F1-Score: 0.6038925205725516 Best-Score: 0.6634079019432532\n",
      "Epoch [11/180] Loss: 0.0428 Time Taken: 57.44173979759216s F1-Score: 0.6377307206021349 Best-Score: 0.6634079019432532\n",
      "Epoch [12/180] Loss: 0.0424 Time Taken: 57.01389408111572s F1-Score: 0.5824712121615714 Best-Score: 0.6634079019432532\n",
      "Epoch [13/180] Loss: 0.0421 Time Taken: 56.43779397010803s F1-Score: 0.578329336391534 Best-Score: 0.6634079019432532\n",
      "Epoch [14/180] Loss: 0.0417 Time Taken: 57.337581634521484s F1-Score: 0.601889556924551 Best-Score: 0.6634079019432532\n",
      "Epoch [15/180] Loss: 0.0412 Time Taken: 55.20521664619446s F1-Score: 0.6144315864856235 Best-Score: 0.6634079019432532\n",
      "Epoch [16/180] Loss: 0.0409 Time Taken: 50.544485569000244s F1-Score: 0.5887435601554002 Best-Score: 0.6634079019432532\n",
      "Epoch [17/180] Loss: 0.0405 Time Taken: 49.275331020355225s F1-Score: 0.5833138057264045 Best-Score: 0.6634079019432532\n",
      "Epoch [18/180] Loss: 0.0402 Time Taken: 54.07914471626282s F1-Score: 0.5973683465196447 Best-Score: 0.6634079019432532\n",
      "Epoch [19/180] Loss: 0.0400 Time Taken: 55.745471477508545s F1-Score: 0.5806145333402981 Best-Score: 0.6634079019432532\n",
      "Epoch [20/180] Loss: 0.0397 Time Taken: 57.53921890258789s F1-Score: 0.6162333205368876 Best-Score: 0.6634079019432532\n",
      "Epoch [21/180] Loss: 0.0395 Time Taken: 53.5570068359375s F1-Score: 0.6427622180120461 Best-Score: 0.6634079019432532\n",
      "Epoch [22/180] Loss: 0.0392 Time Taken: 51.56489610671997s F1-Score: 0.6169254796366679 Best-Score: 0.6634079019432532\n",
      "Epoch [23/180] Loss: 0.0391 Time Taken: 49.62772011756897s F1-Score: 0.5842911844301808 Best-Score: 0.6634079019432532\n",
      "Epoch [24/180] Loss: 0.0390 Time Taken: 52.039039611816406s F1-Score: 0.6178162278714334 Best-Score: 0.6634079019432532\n",
      "Epoch [25/180] Loss: 0.0387 Time Taken: 52.71466398239136s F1-Score: 0.6046800184394763 Best-Score: 0.6634079019432532\n",
      "Epoch [26/180] Loss: 0.0385 Time Taken: 54.20668816566467s F1-Score: 0.5919199128774745 Best-Score: 0.6634079019432532\n",
      "Epoch [27/180] Loss: 0.0382 Time Taken: 57.539576053619385s F1-Score: 0.6164335444201808 Best-Score: 0.6634079019432532\n",
      "Epoch [28/180] Loss: 0.0381 Time Taken: 51.647334575653076s F1-Score: 0.606292195293766 Best-Score: 0.6634079019432532\n",
      "Epoch [29/180] Loss: 0.0379 Time Taken: 54.803728342056274s F1-Score: 0.6329971521066602 Best-Score: 0.6634079019432532\n",
      "Epoch [30/180] Loss: 0.0376 Time Taken: 48.16637325286865s F1-Score: 0.5947258829146198 Best-Score: 0.6634079019432532\n",
      "Epoch [31/180] Loss: 0.0377 Time Taken: 52.534138441085815s F1-Score: 0.6241787288148715 Best-Score: 0.6634079019432532\n",
      "Epoch [32/180] Loss: 0.0376 Time Taken: 51.212668657302856s F1-Score: 0.6082519950535354 Best-Score: 0.6634079019432532\n",
      "Epoch [33/180] Loss: 0.0373 Time Taken: 50.31586956977844s F1-Score: 0.5999798236769112 Best-Score: 0.6634079019432532\n",
      "Epoch [34/180] Loss: 0.0372 Time Taken: 56.78455090522766s F1-Score: 0.6387752464266817 Best-Score: 0.6634079019432532\n",
      "Epoch [35/180] Loss: 0.0371 Time Taken: 50.79119277000427s F1-Score: 0.6414196346640961 Best-Score: 0.6634079019432532\n",
      "Epoch [36/180] Loss: 0.0370 Time Taken: 54.820539236068726s F1-Score: 0.6166428825799783 Best-Score: 0.6634079019432532\n",
      "Epoch [37/180] Loss: 0.0367 Time Taken: 47.21798753738403s F1-Score: 0.6492174116592112 Best-Score: 0.6634079019432532\n",
      "Epoch [38/180] Loss: 0.0367 Time Taken: 52.83563804626465s F1-Score: 0.6299642357653874 Best-Score: 0.6634079019432532\n",
      "Epoch [39/180] Loss: 0.0365 Time Taken: 52.31013560295105s F1-Score: 0.655797413649336 Best-Score: 0.6634079019432532\n",
      "Epoch [40/180] Loss: 0.0363 Time Taken: 50.56213402748108s F1-Score: 0.6398893546477007 Best-Score: 0.6634079019432532\n",
      "Epoch [41/180] Loss: 0.0363 Time Taken: 56.6283495426178s F1-Score: 0.6054369159441771 Best-Score: 0.6634079019432532\n",
      "Epoch [42/180] Loss: 0.0360 Time Taken: 50.45684480667114s F1-Score: 0.6299917722051304 Best-Score: 0.6634079019432532\n",
      "Epoch [43/180] Loss: 0.0358 Time Taken: 54.85826849937439s F1-Score: 0.6334490932651086 Best-Score: 0.6634079019432532\n",
      "Epoch [44/180] Loss: 0.0357 Time Taken: 47.228954792022705s F1-Score: 0.6315525306120213 Best-Score: 0.6634079019432532\n",
      "Epoch [45/180] Loss: 0.0356 Time Taken: 52.84851288795471s F1-Score: 0.6199519286175265 Best-Score: 0.6634079019432532\n",
      "Epoch [46/180] Loss: 0.0355 Time Taken: 52.908554553985596s F1-Score: 0.6513568238136289 Best-Score: 0.6634079019432532\n",
      "Epoch [47/180] Loss: 0.0352 Time Taken: 52.6212203502655s F1-Score: 0.6437138656189533 Best-Score: 0.6634079019432532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       100\n",
      "           1       0.52      0.79      0.63        14\n",
      "           2       0.88      0.94      0.91        52\n",
      "           3       0.90      0.68      0.77        78\n",
      "           4       0.28      0.36      0.31        28\n",
      "           5       0.74      0.62      0.68       108\n",
      "           6       0.38      0.07      0.12        68\n",
      "           7       0.56      0.80      0.66        76\n",
      "           8       0.25      0.55      0.34        38\n",
      "\n",
      "    accuracy                           0.66       562\n",
      "   macro avg       0.61      0.64      0.60       562\n",
      "weighted avg       0.69      0.66      0.65       562\n",
      "\n",
      "Epoch [48/180] Loss: 0.0351 Time Taken: 57.56748676300049s F1-Score: 0.6647619806264979 Best-Score: 0.6647619806264979\n",
      "Epoch [49/180] Loss: 0.0350 Time Taken: 50.95064687728882s F1-Score: 0.6383646717251451 Best-Score: 0.6647619806264979\n",
      "Epoch [50/180] Loss: 0.0348 Time Taken: 52.9087438583374s F1-Score: 0.6173552691425884 Best-Score: 0.6647619806264979\n",
      "Epoch [51/180] Loss: 0.0346 Time Taken: 49.485909938812256s F1-Score: 0.6292365434630652 Best-Score: 0.6647619806264979\n",
      "Epoch [52/180] Loss: 0.0346 Time Taken: 53.67540788650513s F1-Score: 0.628403229547942 Best-Score: 0.6647619806264979\n",
      "Epoch [53/180] Loss: 0.0344 Time Taken: 53.32949256896973s F1-Score: 0.6632505632368028 Best-Score: 0.6647619806264979\n",
      "Epoch [54/180] Loss: 0.0344 Time Taken: 53.23441672325134s F1-Score: 0.6320003500251107 Best-Score: 0.6647619806264979\n",
      "Epoch [55/180] Loss: 0.0343 Time Taken: 56.934730529785156s F1-Score: 0.6526232456144144 Best-Score: 0.6647619806264979\n",
      "Epoch [56/180] Loss: 0.0341 Time Taken: 51.208460569381714s F1-Score: 0.633935231310712 Best-Score: 0.6647619806264979\n",
      "Epoch [57/180] Loss: 0.0341 Time Taken: 51.64975380897522s F1-Score: 0.626518193711288 Best-Score: 0.6647619806264979\n",
      "Epoch [58/180] Loss: 0.0340 Time Taken: 49.42074275016785s F1-Score: 0.6444543051268596 Best-Score: 0.6647619806264979\n",
      "Epoch [59/180] Loss: 0.0338 Time Taken: 52.63004922866821s F1-Score: 0.6546873911385345 Best-Score: 0.6647619806264979\n",
      "Epoch [60/180] Loss: 0.0338 Time Taken: 55.79235482215881s F1-Score: 0.6484945795059632 Best-Score: 0.6647619806264979\n",
      "Epoch [61/180] Loss: 0.0336 Time Taken: 55.481215715408325s F1-Score: 0.653258795492016 Best-Score: 0.6647619806264979\n",
      "Epoch [62/180] Loss: 0.0336 Time Taken: 54.36686372756958s F1-Score: 0.6252634442063335 Best-Score: 0.6647619806264979\n",
      "Epoch [63/180] Loss: 0.0335 Time Taken: 51.82647442817688s F1-Score: 0.650694462550093 Best-Score: 0.6647619806264979\n",
      "Epoch [64/180] Loss: 0.0333 Time Taken: 50.80707263946533s F1-Score: 0.6467574116580981 Best-Score: 0.6647619806264979\n",
      "Epoch [65/180] Loss: 0.0332 Time Taken: 52.867427587509155s F1-Score: 0.6421773910762096 Best-Score: 0.6647619806264979\n",
      "Epoch [66/180] Loss: 0.0332 Time Taken: 51.89526343345642s F1-Score: 0.6523741305162981 Best-Score: 0.6647619806264979\n",
      "Epoch [67/180] Loss: 0.0331 Time Taken: 50.935638427734375s F1-Score: 0.65334753257335 Best-Score: 0.6647619806264979\n",
      "Epoch [68/180] Loss: 0.0330 Time Taken: 56.671154260635376s F1-Score: 0.6518097874188962 Best-Score: 0.6647619806264979\n",
      "Epoch [69/180] Loss: 0.0329 Time Taken: 52.28990817070007s F1-Score: 0.6269071952178378 Best-Score: 0.6647619806264979\n",
      "Epoch [70/180] Loss: 0.0327 Time Taken: 53.088369846343994s F1-Score: 0.6353585019455107 Best-Score: 0.6647619806264979\n",
      "Epoch [71/180] Loss: 0.0326 Time Taken: 49.22803258895874s F1-Score: 0.6517614113980474 Best-Score: 0.6647619806264979\n",
      "Epoch [72/180] Loss: 0.0326 Time Taken: 52.107948541641235s F1-Score: 0.636998639247553 Best-Score: 0.6647619806264979\n",
      "Epoch [73/180] Loss: 0.0326 Time Taken: 51.20197558403015s F1-Score: 0.6435424632006949 Best-Score: 0.6647619806264979\n",
      "Epoch [74/180] Loss: 0.0323 Time Taken: 56.68110418319702s F1-Score: 0.6385091067512991 Best-Score: 0.6647619806264979\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 180\n",
    "prev = time.time()\n",
    "cur_model = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in data_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(torch.float)\n",
    "        labels = labels.to(torch.float)\n",
    "        if torch.cuda.is_available():\n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    cur_model, best_model = Test(test_loader, best_model)\n",
    "    now = time.time()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} Time-Taken: {now-prev}s F1-Score: {cur_model} Best-Score: {best_model}\")\n",
    "    prev = now\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc2f9a",
   "metadata": {},
   "source": [
    "### Evaulation and Results\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfa6afa7-b366-4a38-815f-f752c2ba074a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       100\n",
      "           1       0.42      0.79      0.55        14\n",
      "           2       0.89      0.96      0.93        52\n",
      "           3       0.86      0.65      0.74        78\n",
      "           4       0.17      0.14      0.16        28\n",
      "           5       0.95      0.48      0.64       108\n",
      "           6       0.00      0.00      0.00        68\n",
      "           7       0.43      0.70      0.53        76\n",
      "           8       0.17      0.53      0.26        38\n",
      "\n",
      "    accuracy                           0.59       562\n",
      "   macro avg       0.54      0.58      0.53       562\n",
      "weighted avg       0.65      0.59      0.59       562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "\n",
    "prediction_list = list()\n",
    "labels_list = list()\n",
    "\n",
    "real = []\n",
    "pred = []\n",
    "counter = 0\n",
    "# Disable gradient computation to save memory\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        #print(outputs)\n",
    "        \n",
    "        outputs = outputs.tolist()\n",
    "        labels = labels.tolist()\n",
    "        \n",
    "        pred_labal = outputs[0].index(max(outputs[0]))\n",
    "        \n",
    "\n",
    "        #print(pred_labal)\n",
    "        \n",
    "        #print(labels)\n",
    "        \n",
    "        real_label = labels[0].index(max(labels[0]))\n",
    "        \n",
    "        real.append(real_label)\n",
    "        pred.append(pred_labal)\n",
    "\n",
    "\n",
    "        \n",
    "print(classification_report(real, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc25cb-3c23-41e6-bb6b-5beb134effee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = [0]\n",
    "length = 256\n",
    "\n",
    "for i in range(1,8):\n",
    "    temp.append(int(length/8)*i)\n",
    "    \n",
    "print(temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a18feb-57ea-4c53-a7e2-fdfd576ad4ad",
   "metadata": {},
   "source": [
    "pred = []\n",
    "\n",
    "for inputs, labels in data_loader:\n",
    "    inputs = inputs.to(torch.float)\n",
    "    labels = labels.to(torch.float)\n",
    "    \n",
    "\n",
    "    pred.append(model(inputs).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
