{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686f5bc2",
   "metadata": {},
   "source": [
    "___\n",
    "##### $Name:\\,\\color{blue}{Christopher\\,J.\\,Watson\\,,Nathan\\,Edwards\\,,Paul\\,Thai}$\n",
    "##### $School:\\,\\color{blue}{Marcos\\,School\\,of\\,Engineering,\\,University\\,of\\,San\\,Diego}$\n",
    "##### $Class:\\,\\color{blue}{AAI\\,511-\\,Neural\\,Networks\\,and\\,Learning}$\n",
    "##### $Assignment:\\,\\color{blue}{MSAAI\\,Final\\,Project}$\n",
    "##### $Date:\\,\\color{blue}{8/15/2023}$\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc343580",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13274e2-c25d-4b74-8ebf-4c8c0c18b7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n",
      "GPU Name:  NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "# Libraries \n",
    "\n",
    "# File and Data Handling\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Data Visualization and Numerical Computing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# MIDI Processing\n",
    "import mido\n",
    "\n",
    "# Machine Learning and Deep Learning\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# Machine learning Metrics and Evaluations\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print('GPU Available: ', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU Name: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    device = torch.device(\"cuda:\" + str(torch.cuda.current_device())) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c13ef",
   "metadata": {},
   "source": [
    "### Classes\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2a17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def enum(self,y):\n",
    "        composers = [\"bach\", \"bartok\", \"byrd\", \"chopin\", \"handel\", \"hummel\", \"mendelssohn\",\"mozart\", \"schumann\"]\n",
    "        #print(y)\n",
    "        for i in range(len(composers)):\n",
    "            if composers[i] == y:\n",
    "                slot = i\n",
    "        out = [0] * 9\n",
    "        out[slot] = 1\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        label = self.enum(label)\n",
    "           \n",
    "        \n",
    "        sequence = torch.tensor(sequence)\n",
    "        label = torch.tensor(label)\n",
    "        if torch.cuda.is_available():\n",
    "            label = label.to(device)\n",
    "            #print('GPU Tensor Enabled(Labels):', label.is_cuda)\n",
    "            sequence = sequence.to(device)\n",
    "            #print('GPU Tensor Enabled(Sequences):', sequence.is_cuda)\n",
    "        sequence = sequence[None, :, :] \n",
    "        return sequence, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ffd187",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a13e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(a_dir):\n",
    "    dirs = []\n",
    "    files = []\n",
    "    for name in os.listdir(a_dir):\n",
    "        if os.path.isdir(os.path.join(a_dir, name)):\n",
    "            dirs.append(name)\n",
    "        else:\n",
    "            files.append(name)\n",
    "    return [dirs,files]\n",
    "\n",
    "def create_files_table(top_level, out_file):\n",
    "    temp_comps = []\n",
    "    temp_songs = []\n",
    "    temp_paths = []\n",
    "    \n",
    "    composer_names, songs = get_children(top_level)\n",
    "\n",
    "    for composer in composer_names:\n",
    "        temp_path = top_level + '/' + composer\n",
    "        temp, songs = get_children(temp_path)\n",
    "        for song in songs:\n",
    "            if song != '.DS_Store':\n",
    "                temp_comps.append(composer)\n",
    "                temp_paths.append(temp_path + '/' + song)\n",
    "                temp_songs.append(song.split(\".\")[0])\n",
    "\n",
    "    temp_dict = {'Composers': temp_comps, 'Songs': temp_songs, 'Paths': temp_paths}\n",
    "\n",
    "    table = pd.DataFrame.from_dict(temp_dict)\n",
    "\n",
    "    table.to_csv('./' + out_file + '.csv',index=False)\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n",
    "# Function to extract the notes played in a MIDI file with timestamps\n",
    "def extract_notes_with_meta(midi_filepath):\n",
    "    notes = {}\n",
    "    midi = mido.MidiFile(midi_filepath)\n",
    "    max_time = 0\n",
    "    time_counter = 0\n",
    "    for track in midi.tracks:\n",
    "        time_counter = 0\n",
    "        for msg in track:\n",
    "            time_counter += msg.time\n",
    "            max_time = max(max_time,time_counter)\n",
    "            if msg.type == 'note_on':\n",
    "                if msg.velocity != 0:  # Ensure it's a Note On event\n",
    "                    notes[msg.note] = notes.get(msg.note, []) + [(msg.velocity, time_counter, 1)]  # 1 represents Note On\n",
    "            elif msg.type == 'note_off':\n",
    "                notes[msg.note] = notes.get(msg.note, []) + [(msg.velocity,time_counter, 0)]  # 0 represents Note Off\n",
    "                \n",
    "    return notes, max_time\n",
    "\n",
    "\n",
    "def create_single_sequences(notes, start, tick_count, seq_count): \n",
    "    VEL = 0\n",
    "    TM = 1\n",
    "    ON = 2\n",
    "    \n",
    "    temp_keys = notes.keys()\n",
    "\n",
    "    seq =  [[0] * 128]* seq_count\n",
    "    seq = np.array(seq)\n",
    "\n",
    "    for x in temp_keys:\n",
    "        temp_note = np.array(notes[x])\n",
    "        time_store = 0\n",
    "        for i in range(start, seq_count+start):\n",
    "            temp_vel = 0\n",
    "            for t in range(time_store,temp_note[:,TM].size):\n",
    "                if (temp_note[t,TM]>tick_count*i):\n",
    "                    break\n",
    "                else:\n",
    "                    if temp_note[t,ON] == 1:\n",
    "                        if temp_note[t,VEL] > temp_vel:\n",
    "                            temp_vel = temp_note[t,VEL]\n",
    "                time_store = t\n",
    "            seq[i-start,x] = temp_vel\n",
    "    return seq\n",
    "\n",
    "def sequence_songs(df_songs, tick_count, seq_count, jiggle_on=False):\n",
    "    labels = []\n",
    "    sequences = []\n",
    "    \n",
    "    \n",
    "    shake_amount = [0]\n",
    "    num_jiggle = 3\n",
    "    \n",
    "    if jiggle_on:\n",
    "        for i in range(1,num_jiggle):\n",
    "            shake_amount.append(int(seq_count/num_jiggle)*i)\n",
    "    \n",
    "    for j in shake_amount:\n",
    "        for song in df_songs.iterrows():\n",
    "            song = song[1]\n",
    "            notes, max_time = extract_notes_with_meta(song['Paths'])\n",
    "\n",
    "            for i in range(int((max_time-j)/(seq_count*tick_count))):\n",
    "                sequences.append(create_single_sequences(notes, i*seq_count+j, tick_count, seq_count))\n",
    "                labels.append(song['Composers'])\n",
    "                \n",
    "    return labels, sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d0145",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baba92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "devpath = './Composer_Dataset/NN_midi_files_extended/dev/'\n",
    "testpath = './Composer_Dataset/NN_midi_files_extended/test/'\n",
    "trainpath = './Composer_Dataset/NN_midi_files_extended/train/'\n",
    "\n",
    "dev_table = create_files_table(devpath, 'dev_table')\n",
    "test_table = create_files_table(testpath, 'test_table')\n",
    "train_table = create_files_table(trainpath, 'train_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38ea1d3-2dbd-4a8b-befc-2d2ec5edeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_file_path = './Composer_Dataset/NN_midi_files_extended/dev/bach/bach344.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d65289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1labels, sequences = sequence_songs(train_table, 200, 128,jiggle_on=True)\n",
    "labels, sequences = sequence_songs(train_table,  128, 256,jiggle_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0ddc86-088f-4496-bec5-4a18519e781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1labels_test, sequences_test = sequence_songs(test_table, 200, 128,jiggle_on=True)\n",
    "labels_test, sequences_test = sequence_songs(test_table, 128, 256,jiggle_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3134245-faec-4661-8bb1-bd6be81963bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bach',\n",
       " 'bartok',\n",
       " 'byrd',\n",
       " 'chopin',\n",
       " 'handel',\n",
       " 'hummel',\n",
       " 'mendelssohn',\n",
       " 'mozart',\n",
       " 'schumann'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myset = set(labels_test)\n",
    "myset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2346fe46-e169-42c0-984e-2df368b2ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_notes_with_meta('./Composer_Dataset/NN_midi_files_extended/test/byrd/byrd150.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3d0cc4d-b025-4a19-988f-efaf34735853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bach', 'bartok', 'byrd', 'chopin', 'handel', 'hummel',\n",
       "       'mendelssohn', 'mozart', 'schumann'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dsadasda\n",
    "train_table.Composers.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caac14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset for the dataloader\n",
    "dataset = Dataset(sequences, labels)\n",
    "dataset_test = Dataset(sequences_test, labels_test)\n",
    "\n",
    "# Creating data loader\n",
    "batch_size = 1\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d82b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a82b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df820bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Creation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfd7922c-c399-4931-b7f2-4b598b811bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=2, padding=1)\n",
    "    \n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.LSTM = nn.LSTM(8, 300, 7, batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(4800, 2400)\n",
    "        self.fc2 = nn.Linear(2400, 800)\n",
    "        self.fc3 = nn.Linear(800, 100)\n",
    "        self.fc4 = nn.Linear(100, 9)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv4(x)))\n",
    "\n",
    "        x =  x[:,0,:,:]\n",
    "        h0 = torch.zeros(7, x.size(0), 300)\n",
    "        c0 = torch.zeros(7, x.size(0), 300)     \n",
    "        if torch.cuda.is_available():\n",
    "            h0 = h0.to(device)\n",
    "            #print('GPU Tensor Enabled(labels):', labels.is_cuda)\n",
    "            c0 = c0.to(device)\n",
    "            #print('GPU Tensor Enabled(inputs):', inputs.is_cuda)\n",
    "        x, _ = self.LSTM(x, (h0, c0)) \n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        # return nn.functional.sigmoid(x)\n",
    "        return self.soft(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88fe84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = CNN() \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adagrad(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c7c99",
   "metadata": {},
   "source": [
    "### Training\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31834753-2b6a-4307-b02e-b312ff6425a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Test(dataloader, best_model):\n",
    "    # Evaluating the model\n",
    "    model.eval()\n",
    "\n",
    "    real = []\n",
    "    pred = []\n",
    "    counter = 0\n",
    "    # Disable gradient computation to save memory\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            outputs = outputs.tolist()\n",
    "            labels = labels.tolist()\n",
    "\n",
    "            pred_labal = outputs[0].index(max(outputs[0]))\n",
    "\n",
    "            real_label = labels[0].index(max(labels[0]))\n",
    "\n",
    "            real.append(real_label)\n",
    "            pred.append(pred_labal)\n",
    "            \n",
    "    \n",
    "    score = f1_score(pred, real, average = \"weighted\")\n",
    "    \n",
    "    if score > best_model:\n",
    "        print(classification_report(real, pred))\n",
    "        best_model = score\n",
    "        torch.save(model.state_dict(), 'model_something.pt')\n",
    "    \n",
    "    return score, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "825b4f23-3f94-489f-ad5d-4bd7ca43fbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = 0.6634079019432532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75eec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/180] Loss: 0.0858 Time Taken: 74.74687027931213s F1-Score: 0.47323822425702955 Best-Score: 0.6634079019432532\n",
      "Epoch [2/180] Loss: 0.0759 Time Taken: 72.64150834083557s F1-Score: 0.5136817970920036 Best-Score: 0.6634079019432532\n",
      "Epoch [3/180] Loss: 0.0691 Time Taken: 70.46875524520874s F1-Score: 0.6130836017181166 Best-Score: 0.6634079019432532\n",
      "Epoch [4/180] Loss: 0.0652 Time Taken: 69.28470587730408s F1-Score: 0.6154185837021804 Best-Score: 0.6634079019432532\n",
      "Epoch [5/180] Loss: 0.0632 Time Taken: 68.69155859947205s F1-Score: 0.6022501848051423 Best-Score: 0.6634079019432532\n",
      "Epoch [6/180] Loss: 0.0621 Time Taken: 73.90027403831482s F1-Score: 0.5979268013806113 Best-Score: 0.6634079019432532\n",
      "Epoch [7/180] Loss: 0.0609 Time Taken: 69.62841749191284s F1-Score: 0.5955686416806587 Best-Score: 0.6634079019432532\n",
      "Epoch [8/180] Loss: 0.0600 Time Taken: 70.47327852249146s F1-Score: 0.5833609514813808 Best-Score: 0.6634079019432532\n",
      "Epoch [9/180] Loss: 0.0592 Time Taken: 67.62166690826416s F1-Score: 0.6169987011996658 Best-Score: 0.6634079019432532\n",
      "Epoch [10/180] Loss: 0.0589 Time Taken: 68.95918416976929s F1-Score: 0.6004458956336306 Best-Score: 0.6634079019432532\n",
      "Epoch [11/180] Loss: 0.0581 Time Taken: 71.51610231399536s F1-Score: 0.5825692253305844 Best-Score: 0.6634079019432532\n",
      "Epoch [12/180] Loss: 0.0577 Time Taken: 73.93805742263794s F1-Score: 0.6062345540886276 Best-Score: 0.6634079019432532\n",
      "Epoch [13/180] Loss: 0.0573 Time Taken: 72.20166611671448s F1-Score: 0.5880483207844662 Best-Score: 0.6634079019432532\n",
      "Epoch [14/180] Loss: 0.0569 Time Taken: 67.49220180511475s F1-Score: 0.5862645367113928 Best-Score: 0.6634079019432532\n",
      "Epoch [15/180] Loss: 0.0565 Time Taken: 68.9635591506958s F1-Score: 0.5998752578816948 Best-Score: 0.6634079019432532\n",
      "Epoch [16/180] Loss: 0.0560 Time Taken: 69.96668744087219s F1-Score: 0.5914947810617626 Best-Score: 0.6634079019432532\n",
      "Epoch [17/180] Loss: 0.0557 Time Taken: 69.3364086151123s F1-Score: 0.6088415506062158 Best-Score: 0.6634079019432532\n",
      "Epoch [18/180] Loss: 0.0553 Time Taken: 71.96251344680786s F1-Score: 0.5832769350411602 Best-Score: 0.6634079019432532\n",
      "Epoch [19/180] Loss: 0.0551 Time Taken: 67.79177141189575s F1-Score: 0.5919271855640214 Best-Score: 0.6634079019432532\n",
      "Epoch [20/180] Loss: 0.0547 Time Taken: 71.38930630683899s F1-Score: 0.5975392755473174 Best-Score: 0.6634079019432532\n",
      "Epoch [21/180] Loss: 0.0545 Time Taken: 68.77050971984863s F1-Score: 0.6043698135678776 Best-Score: 0.6634079019432532\n",
      "Epoch [22/180] Loss: 0.0542 Time Taken: 73.21172070503235s F1-Score: 0.5910397762000883 Best-Score: 0.6634079019432532\n",
      "Epoch [23/180] Loss: 0.0537 Time Taken: 74.02587103843689s F1-Score: 0.6056642740563201 Best-Score: 0.6634079019432532\n",
      "Epoch [24/180] Loss: 0.0538 Time Taken: 66.53312540054321s F1-Score: 0.5865289706393797 Best-Score: 0.6634079019432532\n",
      "Epoch [25/180] Loss: 0.0535 Time Taken: 70.982661485672s F1-Score: 0.5863197128446301 Best-Score: 0.6634079019432532\n",
      "Epoch [26/180] Loss: 0.0533 Time Taken: 68.03393697738647s F1-Score: 0.5992068955679825 Best-Score: 0.6634079019432532\n",
      "Epoch [27/180] Loss: 0.0530 Time Taken: 72.5306122303009s F1-Score: 0.5949489760589686 Best-Score: 0.6634079019432532\n",
      "Epoch [28/180] Loss: 0.0528 Time Taken: 70.76678109169006s F1-Score: 0.5971677672452882 Best-Score: 0.6634079019432532\n",
      "Epoch [29/180] Loss: 0.0527 Time Taken: 66.78382420539856s F1-Score: 0.6030710157337471 Best-Score: 0.6634079019432532\n",
      "Epoch [30/180] Loss: 0.0524 Time Taken: 70.65779876708984s F1-Score: 0.6033654617606743 Best-Score: 0.6634079019432532\n",
      "Epoch [31/180] Loss: 0.0523 Time Taken: 72.3022403717041s F1-Score: 0.5898878418647735 Best-Score: 0.6634079019432532\n",
      "Epoch [32/180] Loss: 0.0521 Time Taken: 74.19832468032837s F1-Score: 0.6015733176706148 Best-Score: 0.6634079019432532\n",
      "Epoch [33/180] Loss: 0.0518 Time Taken: 69.678875207901s F1-Score: 0.6119687817784644 Best-Score: 0.6634079019432532\n",
      "Epoch [34/180] Loss: 0.0517 Time Taken: 66.091628074646s F1-Score: 0.5986917917470804 Best-Score: 0.6634079019432532\n",
      "Epoch [35/180] Loss: 0.0515 Time Taken: 70.61836123466492s F1-Score: 0.6020289192339133 Best-Score: 0.6634079019432532\n",
      "Epoch [36/180] Loss: 0.0513 Time Taken: 70.62561511993408s F1-Score: 0.6023624561432006 Best-Score: 0.6634079019432532\n",
      "Epoch [37/180] Loss: 0.0512 Time Taken: 75.32364773750305s F1-Score: 0.6199109882111806 Best-Score: 0.6634079019432532\n",
      "Epoch [38/180] Loss: 0.0511 Time Taken: 71.25540256500244s F1-Score: 0.6057060761376805 Best-Score: 0.6634079019432532\n",
      "Epoch [39/180] Loss: 0.0509 Time Taken: 67.36267900466919s F1-Score: 0.6030634986554385 Best-Score: 0.6634079019432532\n",
      "Epoch [40/180] Loss: 0.0508 Time Taken: 69.9168050289154s F1-Score: 0.6054887297345184 Best-Score: 0.6634079019432532\n",
      "Epoch [41/180] Loss: 0.0506 Time Taken: 75.34547972679138s F1-Score: 0.6002760038533783 Best-Score: 0.6634079019432532\n",
      "Epoch [42/180] Loss: 0.0505 Time Taken: 74.87933325767517s F1-Score: 0.5984633916571523 Best-Score: 0.6634079019432532\n",
      "Epoch [43/180] Loss: 0.0504 Time Taken: 71.16719889640808s F1-Score: 0.6226233699951609 Best-Score: 0.6634079019432532\n",
      "Epoch [44/180] Loss: 0.0502 Time Taken: 68.26665139198303s F1-Score: 0.6056964526819525 Best-Score: 0.6634079019432532\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 180\n",
    "prev = time.time()\n",
    "cur_model = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in data_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(torch.float)\n",
    "        labels = labels.to(torch.float)\n",
    "        if torch.cuda.is_available():\n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    cur_model, best_model = Test(test_loader, best_model)\n",
    "    now = time.time()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} Time Taken: {now-prev}s F1-Score: {cur_model} Best-Score: {best_model}\")\n",
    "    prev = now\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc2f9a",
   "metadata": {},
   "source": [
    "### Evaulation and Results\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa6afa7-b366-4a38-815f-f752c2ba074a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "\n",
    "prediction_list = list()\n",
    "labels_list = list()\n",
    "\n",
    "real = []\n",
    "pred = []\n",
    "counter = 0\n",
    "# Disable gradient computation to save memory\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        #print(outputs)\n",
    "        \n",
    "        outputs = outputs.tolist()\n",
    "        labels = labels.tolist()\n",
    "        \n",
    "        pred_labal = outputs[0].index(max(outputs[0]))\n",
    "        \n",
    "\n",
    "        #print(pred_labal)\n",
    "        \n",
    "        #print(labels)\n",
    "        \n",
    "        real_label = labels[0].index(max(labels[0]))\n",
    "        \n",
    "        real.append(real_label)\n",
    "        pred.append(pred_labal)\n",
    "\n",
    "\n",
    "        \n",
    "print(classification_report(real, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc25cb-3c23-41e6-bb6b-5beb134effee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = [0]\n",
    "length = 256\n",
    "\n",
    "for i in range(1,8):\n",
    "    temp.append(int(length/8)*i)\n",
    "    \n",
    "print(temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a18feb-57ea-4c53-a7e2-fdfd576ad4ad",
   "metadata": {},
   "source": [
    "pred = []\n",
    "\n",
    "for inputs, labels in data_loader:\n",
    "    inputs = inputs.to(torch.float)\n",
    "    labels = labels.to(torch.float)\n",
    "    \n",
    "\n",
    "    pred.append(model(inputs).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
