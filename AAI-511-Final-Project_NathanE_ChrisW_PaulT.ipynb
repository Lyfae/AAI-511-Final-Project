{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686f5bc2",
   "metadata": {},
   "source": [
    "___\n",
    "##### $Name:\\,\\color{blue}{Christopher\\,J.\\,Watson\\,,Nathan\\,Edwards\\,,Paul\\,Thai}$\n",
    "##### $School:\\,\\color{blue}{Marcos\\,School\\,of\\,Engineering,\\,University\\,of\\,San\\,Diego}$\n",
    "##### $Class:\\,\\color{blue}{AAI\\,511-\\,Neural\\,Networks\\,and\\,Learning}$\n",
    "##### $Assignment:\\,\\color{blue}{MSAAI\\,Final\\,Project}$\n",
    "##### $Date:\\,\\color{blue}{8/15/2023}$\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc343580",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13274e2-c25d-4b74-8ebf-4c8c0c18b7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n",
      "GPU Name:  NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "# Libraries \n",
    "\n",
    "# File and Data Handling\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Data Visualization and Numerical Computing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# MIDI Processing\n",
    "import mido\n",
    "\n",
    "# Machine Learning and Deep Learning\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# Machine learning Metrics and Evaluations\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Enable Cuda Development\n",
    "print('GPU Available: ', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU Name: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    device = torch.device(\"cuda:\" + str(torch.cuda.current_device())) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c13ef",
   "metadata": {},
   "source": [
    "### Classes\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2a17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what the data is.\n",
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def enum(self,y):\n",
    "        # set composer list\n",
    "        composers = [\"bach\", \"bartok\", \"byrd\", \"chopin\", \"handel\", \"hummel\", \"mendelssohn\",\"mozart\", \"schumann\"]\n",
    "        #print(y)\n",
    "        for i in range(len(composers)):\n",
    "            if composers[i] == y:\n",
    "                slot = i\n",
    "        out = [0] * 9\n",
    "        out[slot] = 1\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        label = self.enum(label)\n",
    "           \n",
    "        \n",
    "        sequence = torch.tensor(sequence)\n",
    "        label = torch.tensor(label)\n",
    "        # enable cuda cores\n",
    "        if torch.cuda.is_available():\n",
    "            label = label.to(device)\n",
    "            #print('GPU Tensor Enabled(Labels):', label.is_cuda)\n",
    "            sequence = sequence.to(device)\n",
    "            #print('GPU Tensor Enabled(Sequences):', sequence.is_cuda)\n",
    "        sequence = sequence[None, :, :] \n",
    "        return sequence, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ffd187",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a13e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets directory listing\n",
    "def get_children(a_dir):\n",
    "    dirs = []\n",
    "    files = []\n",
    "    for name in os.listdir(a_dir):\n",
    "        if os.path.isdir(os.path.join(a_dir, name)):\n",
    "            dirs.append(name)\n",
    "        else:\n",
    "            files.append(name)\n",
    "    return [dirs,files]\n",
    "\n",
    "# Creates tables from files in directory \n",
    "def create_files_table(top_level, out_file):\n",
    "    temp_comps = []\n",
    "    temp_songs = []\n",
    "    temp_paths = []\n",
    "    \n",
    "    composer_names, songs = get_children(top_level)\n",
    "\n",
    "    for composer in composer_names:\n",
    "        temp_path = top_level + '/' + composer\n",
    "        temp, songs = get_children(temp_path)\n",
    "        for song in songs:\n",
    "            if song != '.DS_Store':\n",
    "                temp_comps.append(composer)\n",
    "                temp_paths.append(temp_path + '/' + song)\n",
    "                temp_songs.append(song.split(\".\")[0])\n",
    "\n",
    "    temp_dict = {'Composers': temp_comps, 'Songs': temp_songs, 'Paths': temp_paths}\n",
    "\n",
    "    table = pd.DataFrame.from_dict(temp_dict)\n",
    "\n",
    "    table.to_csv('./' + out_file + '.csv',index=False)\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n",
    "# Function to extract the notes played in a MIDI file with timestamps\n",
    "def extract_notes_with_meta(midi_filepath):\n",
    "    notes = {}\n",
    "    midi = mido.MidiFile(midi_filepath)\n",
    "    max_time = 0\n",
    "    time_counter = 0\n",
    "    for track in midi.tracks:\n",
    "        time_counter = 0\n",
    "        for msg in track:\n",
    "            time_counter += msg.time\n",
    "            max_time = max(max_time,time_counter)\n",
    "            if msg.type == 'note_on':\n",
    "                if msg.velocity != 0:  # Ensure it's a Note On event\n",
    "                    notes[msg.note] = notes.get(msg.note, []) + [(msg.velocity, time_counter, 1)]  # 1 represents Note On\n",
    "            elif msg.type == 'note_off':\n",
    "                notes[msg.note] = notes.get(msg.note, []) + [(msg.velocity,time_counter, 0)]  # 0 represents Note Off\n",
    "                \n",
    "    return notes, max_time\n",
    "\n",
    "# Creates a single sequence from a song as a sample for training\n",
    "def create_single_sequences(notes, start, tick_count, seq_count): \n",
    "    VEL = 0\n",
    "    TM = 1\n",
    "    ON = 2\n",
    "    \n",
    "    temp_keys = notes.keys()\n",
    "\n",
    "    seq =  [[0] * 128]* seq_count\n",
    "    seq = np.array(seq)\n",
    "\n",
    "    for x in temp_keys:\n",
    "        temp_note = np.array(notes[x])\n",
    "        time_store = 0\n",
    "        for i in range(start, seq_count+start):\n",
    "            temp_vel = 0\n",
    "            for t in range(time_store,temp_note[:,TM].size):\n",
    "                if (temp_note[t,TM]>tick_count*i):\n",
    "                    break\n",
    "                else:\n",
    "                    if temp_note[t,ON] == 1:\n",
    "                        if temp_note[t,VEL] > temp_vel:\n",
    "                            temp_vel = temp_note[t,VEL]\n",
    "                time_store = t\n",
    "            seq[i-start,x] = temp_vel\n",
    "    return seq\n",
    "\n",
    "# Sequences all songs in a table\n",
    "def sequence_songs(df_songs, tick_count, seq_count, jiggle_on=False):\n",
    "    # temp variables\n",
    "    labels = []\n",
    "    sequences = []\n",
    "    \n",
    "    # shake variable\n",
    "    shake_amount = [0]\n",
    "    \n",
    "    # jiggle the content of the data\n",
    "    if jiggle_on:\n",
    "        shake_amount = [0, int(seq_count/2)]\n",
    "    \n",
    "    # main data loop\n",
    "    for j in shake_amount:\n",
    "        for song in df_songs.iterrows():\n",
    "            temp_count = tick_count\n",
    "            song = song[1]\n",
    "            notes, max_time = extract_notes_with_meta(song['Paths'])\n",
    "            if max_time / tick_count < seq_count:\n",
    "                temp_count = int((max_time / seq_count)*.8)\n",
    "            for i in range(int((max_time-j)/(seq_count*temp_count))):\n",
    "                sequences.append(create_single_sequences(notes, i*seq_count+j, temp_count, seq_count))\n",
    "                labels.append(song['Composers'])\n",
    "                \n",
    "    return labels, sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d0145",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baba92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the data paths for the dataset\n",
    "devpath = './Composer_Dataset/NN_midi_files_extended/dev/'\n",
    "testpath = './Composer_Dataset/NN_midi_files_extended/test/'\n",
    "trainpath = './Composer_Dataset/NN_midi_files_extended/train/'\n",
    "\n",
    "# create tables for each set\n",
    "dev_table = create_files_table(devpath, 'dev_table')\n",
    "test_table = create_files_table(testpath, 'test_table')\n",
    "train_table = create_files_table(trainpath, 'train_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d65289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was the various samplings used in conjuction with transfer learning\n",
    "#1labels, sequences = sequence_songs(train_table, 200, 128,jiggle_on=True)\n",
    "labels, sequences = sequence_songs(train_table, 300, 128,jiggle_on=True)\n",
    "#2labels, sequences = sequence_songs(train_table,  128, 128,jiggle_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0ddc86-088f-4496-bec5-4a18519e781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was the various samplings used in conjuction with transfer learning\n",
    "#1labels_test, sequences_test = sequence_songs(test_table, 200, 128,jiggle_on=True)\n",
    "labels_test, sequences_test = sequence_songs(test_table, 300, 128,jiggle_on=True)\n",
    "#2labels_test, sequences_test = sequence_songs(test_table, 128, 128,jiggle_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3134245-faec-4661-8bb1-bd6be81963bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bach',\n",
       " 'bartok',\n",
       " 'byrd',\n",
       " 'chopin',\n",
       " 'handel',\n",
       " 'hummel',\n",
       " 'mendelssohn',\n",
       " 'mozart',\n",
       " 'schumann'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all the composers\n",
    "myset = set(labels_test)\n",
    "myset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3d0cc4d-b025-4a19-988f-efaf34735853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bach', 'bartok', 'byrd', 'chopin', 'handel', 'hummel',\n",
       "       'mendelssohn', 'mozart', 'schumann'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all composers in the table\n",
    "train_table.Composers.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caac14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset for the dataloader\n",
    "dataset = Dataset(sequences, labels)\n",
    "dataset_test = Dataset(sequences_test, labels_test)\n",
    "\n",
    "# Creating data loader\n",
    "batch_size = 1\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d82b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a82b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df820bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Creation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfd7922c-c399-4931-b7f2-4b598b811bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=2, padding=1)\n",
    "    \n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.LSTM = nn.LSTM(8, 300, 7, batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(2400, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 600)\n",
    "        self.fc3 = nn.Linear(600, 100)\n",
    "        self.fc4 = nn.Linear(100, 9)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv4(x)))\n",
    "\n",
    "        x =  x[:,0,:,:]\n",
    "        h0 = torch.zeros(7, x.size(0), 300)\n",
    "        c0 = torch.zeros(7, x.size(0), 300)     \n",
    "        if torch.cuda.is_available():\n",
    "            h0 = h0.to(device)\n",
    "            #print('GPU Tensor Enabled(labels):', labels.is_cuda)\n",
    "            c0 = c0.to(device)\n",
    "            #print('GPU Tensor Enabled(inputs):', inputs.is_cuda)\n",
    "        x, _ = self.LSTM(x, (h0, c0)) \n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        # return nn.functional.sigmoid(x)\n",
    "        return self.soft(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9374daab-2a1b-46d0-a166-575e60220c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = CNN() \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adagrad(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "825b4f23-3f94-489f-ad5d-4bd7ca43fbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This was the score of our best model which can be imported through the model load function\n",
    "best_model = 0.7245685124246504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9deab72f-014a-430f-af2e-26b33e47fb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load state of previous model\n",
    "model.load_state_dict(torch.load('best-model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c7c99",
   "metadata": {},
   "source": [
    "### Training\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31834753-2b6a-4307-b02e-b312ff6425a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Test(dataloader, best_model):\n",
    "    # Evaluating the model\n",
    "    model.eval()\n",
    "\n",
    "    real = []\n",
    "    pred = []\n",
    "    counter = 0\n",
    "    # Disable gradient computation to save memory\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            outputs = outputs.tolist()\n",
    "            labels = labels.tolist()\n",
    "\n",
    "            pred_labal = outputs[0].index(max(outputs[0]))\n",
    "\n",
    "            real_label = labels[0].index(max(labels[0]))\n",
    "\n",
    "            real.append(real_label)\n",
    "            pred.append(pred_labal)\n",
    "            \n",
    "    # scoring metric\n",
    "    score = f1_score(pred, real, average = \"weighted\")\n",
    "    \n",
    "    Enable best save\n",
    "    if score > best_model:\n",
    "        print(classification_report(real, pred))\n",
    "        best_model = score\n",
    "        torch.save(model.state_dict(), 'model_something.pt')\n",
    "    \n",
    "    return score, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b75eec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] Loss: 0.0210 Time-Taken: 32.40267491340637s F1-Score: 0.6959843236492259 Best-Score: 0.7175077123970345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        58\n",
      "           1       0.33      0.40      0.36        10\n",
      "           2       0.86      1.00      0.92        30\n",
      "           3       0.87      0.69      0.77        48\n",
      "           4       0.39      0.39      0.39        18\n",
      "           5       0.85      0.81      0.83        62\n",
      "           6       0.59      0.42      0.49        40\n",
      "           7       0.66      0.84      0.74        44\n",
      "           8       0.35      0.50      0.41        24\n",
      "\n",
      "    accuracy                           0.73       334\n",
      "   macro avg       0.66      0.66      0.65       334\n",
      "weighted avg       0.75      0.73      0.73       334\n",
      "\n",
      "Epoch [2/3] Loss: 0.0206 Time-Taken: 29.49116611480713s F1-Score: 0.7245685124246504 Best-Score: 0.7245685124246504\n",
      "Epoch [3/3] Loss: 0.0205 Time-Taken: 30.71710443496704s F1-Score: 0.700046913635001 Best-Score: 0.7245685124246504\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 3\n",
    "prev = time.time()\n",
    "cur_model = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in data_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(torch.float)\n",
    "        labels = labels.to(torch.float)\n",
    "        if torch.cuda.is_available():\n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the stats loss for the epoch\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    cur_model, best_model = Test(test_loader, best_model)\n",
    "    now = time.time()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} Time-Taken: {now-prev}s F1-Score: {cur_model} Best-Score: {best_model}\")\n",
    "    prev = now\n",
    "\n",
    "# we never once reached this statement except to show of this notebook at the end.\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc2f9a",
   "metadata": {},
   "source": [
    "### Evaluation and Results\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "778c5d93-c63d-4e98-bcda-c0be8a271dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        58\n",
      "           1       0.29      0.40      0.33        10\n",
      "           2       0.83      1.00      0.91        30\n",
      "           3       0.76      0.73      0.74        48\n",
      "           4       0.53      0.44      0.48        18\n",
      "           5       0.91      0.77      0.83        62\n",
      "           6       0.54      0.38      0.44        40\n",
      "           7       0.61      0.82      0.70        44\n",
      "           8       0.23      0.29      0.25        24\n",
      "\n",
      "    accuracy                           0.70       334\n",
      "   macro avg       0.63      0.64      0.63       334\n",
      "weighted avg       0.72      0.70      0.71       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "\n",
    "prediction_list = list()\n",
    "labels_list = list()\n",
    "\n",
    "real = []\n",
    "pred = []\n",
    "counter = 0\n",
    "# Disable gradient computation to save memory\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        #print(outputs)\n",
    "        \n",
    "        outputs = outputs.tolist()\n",
    "        labels = labels.tolist()\n",
    "        \n",
    "        pred_labal = outputs[0].index(max(outputs[0]))\n",
    "        \n",
    "\n",
    "        #print(pred_labal)\n",
    "        \n",
    "        #print(labels)\n",
    "        \n",
    "        real_label = labels[0].index(max(labels[0]))\n",
    "        \n",
    "        real.append(real_label)\n",
    "        pred.append(pred_labal)\n",
    "\n",
    "\n",
    "        \n",
    "print(classification_report(real, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51265029-439f-4490-a039-d9a76f4f7435",
   "metadata": {
    "tags": []
   },
   "source": [
    "Considering how many times the model was loaded and retrained with different variations of the train data, sometimes the results varied per run slightly. We never reached an end conclusion of how accurate our model could get because we were limited on training time but these are some of our demonstrated results. Our best scores had an F1-Score of .724 and an accuracy of 73%. We consider this to be adequate results and our thoughts for improvements are documented in the final report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
