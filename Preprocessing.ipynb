{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f13274e2-c25d-4b74-8ebf-4c8c0c18b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "import os\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d67db43-0234-42f6-9509-c27f240c284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiTranscriber():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "    def Sequence(self, track):\n",
    "        result = []\n",
    "        notes = {}\n",
    "        time = 0\n",
    "        final_result = []\n",
    "        data = [] \n",
    "        state = [0] * 128\n",
    "        tick_counter = 0\n",
    "        \n",
    "        tick_interval = 20\n",
    "        \n",
    "        for i in range(16):\n",
    "            data.append(state)\n",
    "            \n",
    "        for msg in track:\n",
    "            time += msg.time\n",
    "            tick_counter += msg.time\n",
    "            \n",
    "            if(tick_counter > tick_interval):\n",
    "                final_result.append(data)\n",
    "                tick_counter = 0\n",
    "            \n",
    "            if msg.type == 'note_on':\n",
    "                if msg.velocity != 0:\n",
    "                    past = notes.get(msg.note)\n",
    "                    if(past == None):\n",
    "                        past = []\n",
    "                    notes[msg.note] = past + [time , 1] \n",
    "                    result.append([time, msg.note, msg.velocity,  msg.channel, msg.type])\n",
    "                    data[msg.channel][msg.note] = msg.velocity\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "            if msg.type == 'note_off':\n",
    "                past = notes.get(msg.note)\n",
    "                if(past == None):\n",
    "                    past = []\n",
    "                notes[msg.note] = past + [time , 0]\n",
    "                result.append([time ,msg.note, msg.velocity ,  msg.channel, msg.type])\n",
    "                data[msg.channel][msg.note] = 0\n",
    "                \n",
    "        return result, data, final_result\n",
    "        \n",
    "        \n",
    "    def BuildArray(self,midi):\n",
    "        Lenghth = [len(tr) for tr in midi.tracks]\n",
    "        track_length = max(Lenghth)\n",
    "        min_track =  track_length/10 #Only accept tracks 1/10 of length.\n",
    "        all_arys = []\n",
    "        training = []\n",
    "        for track in range(len(midi.tracks)):\n",
    "            out = []\n",
    "            valid_track = (len(midi.tracks[track]) > min_track)\n",
    "            if(valid_track):\n",
    "                track = midi.tracks[track]\n",
    "                res, data, final_result = self.Sequence(track)\n",
    "                \n",
    "                #print(len(final_result))\n",
    "                \n",
    "                \n",
    "                all_arys.append(res)\n",
    "                training.append(data)\n",
    "            \n",
    "        #sums = all_arys.sum(axis=1)\n",
    "        #ends = np.where(sums > 0)[0]\n",
    "        return all_arys, data, final_result\n",
    "\n",
    "        builder = []\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8d03a2-23e8-4487-abc9-4aca18d39fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scriber = MidiTranscriber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727c4757-6fbb-4a01-b865-fffa4e885ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parser(composer, path):\n",
    "    midis = os.listdir(path)\n",
    "    \n",
    "    pair = []\n",
    "    \n",
    "    for file in midis:\n",
    "        if(file == \".DS_Store\"):\n",
    "            continue \n",
    "        midis_path = path + \"/\" + file\n",
    "        #print(midis_path)\n",
    "        \n",
    "        midi = mido.MidiFile(midis_path)\n",
    "        #print(len(midi.tracks[0]) + len(midi.tracks[1]) + len(midi.tracks[2]))\n",
    "        #print(len(midi.tracks[0]))\n",
    "        arr, data, final_result = scriber.BuildArray(midi)\n",
    "        \n",
    "        \n",
    "        sequence_size = 100\n",
    "        \n",
    "        div = len(final_result) / sequence_size\n",
    "        last = 0\n",
    "        for i in range(int(div)):\n",
    "\n",
    "            clip = final_result[last:sequence_size*int((i+1))]\n",
    "            last = int(sequence_size)*(i+1)\n",
    "            \n",
    "            x = clip\n",
    "            y= composer\n",
    " \n",
    "            pair.append([x,y])\n",
    "    \n",
    "            if(not len(x) == 100):\n",
    "                print(len(x))\n",
    "        \n",
    "    return arr, data, final_result, pair\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38ea1d3-2dbd-4a8b-befc-2d2ec5edeeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bach\n",
      "bartok\n",
      "byrd\n",
      "chopin\n",
      "handel\n",
      "hummel\n",
      "mendelssohn\n",
      "mozart\n",
      "schumann\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Composer_Dataset/NN_midi_files_extended/train\"\n",
    "composers = ['bach', 'bartok', 'byrd', 'chopin', 'handel', 'hummel', 'mendelssohn', 'mozart', 'schumann']\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for composer in composers:\n",
    "    path = dataset +\"/\"+ composer\n",
    "    print(composer)\n",
    "    arr, data, final_result,pair = Parser(composer, path)\n",
    "    #print(len(pair))\n",
    "    pairs.append(pair)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9a20466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bach\n",
      "bartok\n",
      "byrd\n",
      "chopin\n",
      "handel\n",
      "hummel\n",
      "mendelssohn\n",
      "mozart\n",
      "schumann\n"
     ]
    }
   ],
   "source": [
    "dataset_test = \"Composer_Dataset/NN_midi_files_extended/test\"\n",
    "\n",
    "test = []\n",
    "\n",
    "for composer in composers:\n",
    "    path = dataset_test +\"/\"+ composer\n",
    "    print(composer)\n",
    "    arr, data, final_result,pair = Parser(composer, path)\n",
    "    #print(len(pair))\n",
    "    test.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe511b66-dc6e-4c41-b760-64055302bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7de3604-c6e9-40cc-bacd-271ca02a6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = np.array(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bba6fbe-73d5-4ae7-9a38-d112634aa6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1736, 16, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "def01338-17be-4266-8517-a51028f4ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = []\n",
    "for i in pairs:\n",
    "    for j in i:\n",
    "        pair.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b62ae14-e16a-4f3f-b679-c5e54784e1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5598"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e401082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "test_pair = []\n",
    "for i in test:\n",
    "    for j in i:\n",
    "        test_pair.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d77240ab-778a-4693-bf6b-b64347fccec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuik\\AppData\\Local\\Temp/ipykernel_25020/2379020598.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test = np.array(pair)\n"
     ]
    }
   ],
   "source": [
    "test = np.array(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d68a388-97c5-4e14-93a3-92ff03f66f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "     \n",
    "    def enum(self,y):\n",
    "        composers = [\"bach\", \"bartok\", \"byrd\", \"chopin\", \"handel\", \"hummel\", \"mendelssohn\",\"mozart\", \"schumann\"]\n",
    "        #print(y)\n",
    "        for i in range(len(composers)):\n",
    "            if composers[i] == y:\n",
    "                slot = i\n",
    "        out = [0] * 9\n",
    "        out[slot] = 1\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def __init__(self, pair):\n",
    "        self.pair = pair\n",
    "    def __len__(self):\n",
    "        return len(self.pair)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        x = torch.tensor(self.pair[idx][0])\n",
    "        y = torch.tensor(self.enum(self.pair[idx][1]))\n",
    "        return x,y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92f22077-9492-42f9-8986-42968368e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c649f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c456f4fd-b7e0-41ce-ac65-fb51201e4854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 16, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1000][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "741e2f81-3a96-4d47-b853-1056bbdb97df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a66b950-70ab-4392-9e04-ce2f0ffbd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data,batch_size=3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f4fd65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70f25db3-01ec-410a-bc61-5c7ecab431cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1866"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df820bc",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd7922c-c399-4931-b7f2-4b598b811bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# class CNN(nn.Module):\n",
    "#     # Constructor\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         # Self initialize the Convolution, Pooling, and Fully Connected Layer\n",
    "#         self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(16 * 128 , 128)\n",
    "#         self.fc2 = nn.Linear(128, len(train_dataloader))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Normalize, Pool, Flatten to 1D and then create Fully Connected Layer\n",
    "#         x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "#         x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = nn.functional.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "\n",
    "#         return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(100, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 2 * 64, 128) \n",
    "        self.fc2 = nn.Linear(128, 9)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "# Creating the Long Short Term Memory model class\n",
    "class LSTM(nn.Module):\n",
    "    # create the constructor of our RNN\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM,self).__init__()\n",
    "        # self initialize the hidden size LSTM, and fully connected layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Initialize the hidden state and cell state\n",
    "        hidden_state = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        cell_state = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # grabbing the ouput of the hidden state\n",
    "        output_state, _ = self.lstm(x, (hidden_state, cell_state))\n",
    "\n",
    "        # pass output state into through the fully connected layer\n",
    "        output_state = self.fc(output_state[:, -1, :])\n",
    "\n",
    "        return output_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88fe84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = CNN() \n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b75eec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 5.4232\n",
      "Epoch [2/10] Loss: 5.4219\n",
      "Epoch [3/10] Loss: 5.4205\n",
      "Epoch [4/10] Loss: 5.4197\n",
      "Epoch [5/10] Loss: 5.4193\n",
      "Epoch [6/10] Loss: 5.4190\n",
      "Epoch [7/10] Loss: 5.4188\n",
      "Epoch [8/10] Loss: 5.4187\n",
      "Epoch [9/10] Loss: 5.4185\n",
      "Epoch [10/10] Loss: 5.4184\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(torch.float)\n",
    "        labels = labels.to(torch.float)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Reshpae the label tensor to 1D\n",
    "        #labels = labels.view(-1)\n",
    "        #print(\"Outputs:\",outputs.shape)\n",
    "        #print(\"Labels:\", labels.shape)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a90dec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25020/602714733.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Disable gradient computation to save memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\usuik\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\usuik\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\usuik\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\usuik\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25020/37174296.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "\n",
    "prediction_list = list()\n",
    "labels_list = list()\n",
    "\n",
    "# Disable gradient computation to save memory\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        prediction_list.extend(predicted.numpy())\n",
    "        labels_list.extend(labels.numpy())\n",
    "\n",
    "# Finding accuracy, precision, f1 score and confusion matrix\n",
    "accuracy = accuracy_score(labels_list, prediction_list)\n",
    "precision = precision_score(labels_list, prediction_list, average='weighted')\n",
    "f1_score = f1_score(labels_list, prediction_list, average='weighted')\n",
    "confusion_mtrx = confusion_matrix(labels_list, prediction_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
