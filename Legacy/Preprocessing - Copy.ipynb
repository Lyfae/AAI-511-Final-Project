{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f13274e2-c25d-4b74-8ebf-4c8c0c18b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "import os\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3d67db43-0234-42f6-9509-c27f240c284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiTranscriber():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "    def Sequence(self, track):\n",
    "        result = []\n",
    "        notes = {}\n",
    "        time = 0\n",
    "        final_result = []\n",
    "        data = [] \n",
    "        state = [0] * 128\n",
    "        tick_counter = 0\n",
    "        \n",
    "        tick_interval = 25\n",
    "        \n",
    "        for i in range(16):\n",
    "            data.append(state)\n",
    "            \n",
    "        for msg in track:\n",
    "            time += msg.time\n",
    "            tick_counter += msg.time\n",
    "            \n",
    "            if(tick_counter > tick_interval):\n",
    "                final_result.append(data)\n",
    "                tick_counter = 0\n",
    "            \n",
    "            if msg.type == 'note_on':\n",
    "                if msg.velocity != 0:\n",
    "                    past = notes.get(msg.note)\n",
    "                    if(past == None):\n",
    "                        past = []\n",
    "                    notes[msg.note] = past + [time , 1] \n",
    "                    result.append([time, msg.note, msg.velocity,  msg.channel, msg.type])\n",
    "                    data[msg.channel][msg.note] = msg.velocity\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "            if msg.type == 'note_off':\n",
    "                past = notes.get(msg.note)\n",
    "                if(past == None):\n",
    "                    past = []\n",
    "                notes[msg.note] = past + [time , 0]\n",
    "                result.append([time ,msg.note, msg.velocity ,  msg.channel, msg.type])\n",
    "                data[msg.channel][msg.note] = 0\n",
    "                \n",
    "        return result, data, final_result\n",
    "        \n",
    "        \n",
    "    def BuildArray(self,midi):\n",
    "        Lenghth = [len(tr) for tr in midi.tracks]\n",
    "        track_length = max(Lenghth)\n",
    "        min_track =  track_length/10 #Only accept tracks 1/10 of length.\n",
    "        all_arys = []\n",
    "        training = []\n",
    "        for track in range(len(midi.tracks)):\n",
    "            out = []\n",
    "            valid_track = (len(midi.tracks[track]) > min_track)\n",
    "            if(valid_track):\n",
    "                track = midi.tracks[track]\n",
    "                res, data, final_result = self.Sequence(track)\n",
    "                \n",
    "                #print(len(final_result))\n",
    "                \n",
    "                \n",
    "                all_arys.append(res)\n",
    "\n",
    "        return all_arys, data, final_result\n",
    "\n",
    "        builder = []\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ec8d03a2-23e8-4487-abc9-4aca18d39fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scriber = MidiTranscriber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "727c4757-6fbb-4a01-b865-fffa4e885ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parser(composer, path):\n",
    "    midis = os.listdir(path)\n",
    "    \n",
    "    pair = []\n",
    "    \n",
    "    for file in midis:\n",
    "        if(file == \".DS_Store\"):\n",
    "            continue \n",
    "        midis_path = path + \"/\" + file\n",
    "        #print(midis_path)\n",
    "        \n",
    "        midi = mido.MidiFile(midis_path)\n",
    "        #print(len(midi.tracks[0]) + len(midi.tracks[1]) + len(midi.tracks[2]))\n",
    "        #print(len(midi.tracks[0]))\n",
    "        arr, data, final_result = scriber.BuildArray(midi)\n",
    "        \n",
    "        \n",
    "        sequence_size = 1000\n",
    "        \n",
    "        div = len(final_result) / sequence_size\n",
    "        last = 0\n",
    "        for i in range(int(div)):\n",
    "\n",
    "            clip = final_result[last:sequence_size*int((i+1))]\n",
    "            last = int(sequence_size)*(i+1)\n",
    "            \n",
    "            x = clip\n",
    "            y= composer\n",
    " \n",
    "            pair.append([x,y])\n",
    "    \n",
    "            #if(not len(x) == 100):\n",
    "             #   print(len(x))\n",
    "        \n",
    "    return arr, data, final_result, pair\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a38ea1d3-2dbd-4a8b-befc-2d2ec5edeeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bach\n",
      "bartok\n",
      "byrd\n",
      "chopin\n",
      "handel\n",
      "hummel\n",
      "mendelssohn\n",
      "mozart\n",
      "schumann\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Composer_Dataset/NN_midi_files_extended/train\"\n",
    "composers = ['bach', 'bartok', 'byrd', 'chopin', 'handel', 'hummel', 'mendelssohn', 'mozart', 'schumann']\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for composer in composers:\n",
    "    path = dataset +\"/\"+ composer\n",
    "    print(composer)\n",
    "    arr, data, final_result,pair = Parser(composer, path)\n",
    "    #print(len(pair))\n",
    "    pairs.append(pair)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d9a20466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bach\n",
      "bartok\n",
      "byrd\n",
      "chopin\n",
      "handel\n",
      "hummel\n",
      "mendelssohn\n",
      "mozart\n",
      "schumann\n"
     ]
    }
   ],
   "source": [
    "dataset_test = \"Composer_Dataset/NN_midi_files_extended/test\"\n",
    "\n",
    "test = []\n",
    "\n",
    "for composer in composers:\n",
    "    path = dataset_test +\"/\"+ composer\n",
    "    print(composer)\n",
    "    arr, data, final_result,pair = Parser(composer, path)\n",
    "    #print(len(pair))\n",
    "    test.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fe511b66-dc6e-4c41-b760-64055302bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 128)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c7de3604-c6e9-40cc-bacd-271ca02a6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = np.array(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0bba6fbe-73d5-4ae7-9a38-d112634aa6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2726, 16, 128)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "def01338-17be-4266-8517-a51028f4ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = []\n",
    "for i in pairs:\n",
    "    for j in i:\n",
    "        pair.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2b62ae14-e16a-4f3f-b679-c5e54784e1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e401082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "test_pair = []\n",
    "for i in test:\n",
    "    for j in i:\n",
    "        test_pair.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6d68a388-97c5-4e14-93a3-92ff03f66f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "     \n",
    "    def enum(self,y):\n",
    "        composers = [\"bach\", \"bartok\", \"byrd\", \"chopin\", \"handel\", \"hummel\", \"mendelssohn\",\"mozart\", \"schumann\"]\n",
    "        #print(y)\n",
    "        for i in range(len(composers)):\n",
    "            if composers[i] == y:\n",
    "                slot = i\n",
    "        out = [0] * 9\n",
    "        out[slot] = 1\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def __init__(self, pair):\n",
    "        self.pair = pair\n",
    "    def __len__(self):\n",
    "        return len(self.pair)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        x = torch.tensor(self.pair[idx][0])\n",
    "        x = torch.swapaxes(x, 0, 1)\n",
    "        y = torch.tensor(self.enum(self.pair[idx][1]))\n",
    "        return x,y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "92f22077-9492-42f9-8986-42968368e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c649f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Dataset(test_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "534140f7-d04a-460d-af69-5c022eae2d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c456f4fd-b7e0-41ce-ac65-fb51201e4854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1000, 128])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[100][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "45a82965-02a5-4485-8333-87928e85af55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "741e2f81-3a96-4d47-b853-1056bbdb97df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1a66b950-70ab-4392-9e04-ce2f0ffbd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data,batch_size=3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9f4fd65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "70f25db3-01ec-410a-bc61-5c7ecab431cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df820bc",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "dfd7922c-c399-4931-b7f2-4b598b811bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# class CNN(nn.Module):\n",
    "#     # Constructor\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         # Self initialize the Convolution, Pooling, and Fully Connected Layer\n",
    "#         self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(16 * 128 , 128)\n",
    "#         self.fc2 = nn.Linear(128, len(train_dataloader))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Normalize, Pool, Flatten to 1D and then create Fully Connected Layer\n",
    "#         x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "#         x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = nn.functional.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "\n",
    "#         return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 1, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.LSTM= nn.LSTM(32, 10, 1, batch_first=True)\n",
    "                           \n",
    "        self.fc1 = nn.Linear(2500, 128) \n",
    "        self.fc3 = nn.Linear(128, 9)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        #print(x.shape)         \n",
    "        x =  x[:,0,:,:]\n",
    "        h0 = torch.zeros(1, x.size(0), 10)\n",
    "        c0 = torch.zeros(1, x.size(0), 10)        \n",
    "        x, _ = self.LSTM(x, (h0, c0))               \n",
    "                                       \n",
    "        \n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return nn.functional.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "88fe84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = CNN() \n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75eec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 2.0150\n",
      "Epoch [2/10] Loss: 1.9395\n",
      "Epoch [3/10] Loss: 1.9234\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(torch.float)\n",
    "        labels = labels.to(torch.float)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Reshpae the label tensor to 1D\n",
    "        #labels = labels.view(-1)\n",
    "        #print(\"Outputs:\",outputs.shape)\n",
    "        #print(\"Labels:\", labels.shape)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "\n",
    "prediction_list = list()\n",
    "labels_list = list()\n",
    "\n",
    "real = []\n",
    "pred = []\n",
    "\n",
    "# Disable gradient computation to save memory\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        print(outputs)\n",
    "        \n",
    "        outputs = outputs.tolist()\n",
    "        labels = labels.tolist()\n",
    "        \n",
    "        pred_labal = outputs[0].index(max(outputs[0]))\n",
    "        \n",
    "        \n",
    "        print(pred_labal)\n",
    "        \n",
    "        print(labels)\n",
    "        \n",
    "        real_label = labels[0].index(max(labels[0]))\n",
    "        \n",
    "        real.append(real_label)\n",
    "        pred.append(pred_labal)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6baef871-f2c8-46d7-891a-35b4a9e3f234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a0f84cff-ac88-4bca-a4cb-976204817809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 8]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2e4d8e01-dcd8-44e6-92e6-00a94a05e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had a accuracy_score socre of :  0.05\n"
     ]
    }
   ],
   "source": [
    "print(\"The model had a accuracy_score socre of : \", round(accuracy_score(pred, real),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ed747-8e9b-4946-89c9-42e32983b314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
