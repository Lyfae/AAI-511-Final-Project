{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686f5bc2",
   "metadata": {},
   "source": [
    "___\n",
    "##### $Name:\\,\\color{blue}{Christopher\\,J.\\,Watson\\,,Nathan\\,Edwards\\,,Paul\\,Thai}$\n",
    "##### $School:\\,\\color{blue}{Marcos\\,School\\,of\\,Engineering,\\,University\\,of\\,San\\,Diego}$\n",
    "##### $Class:\\,\\color{blue}{AAI\\,511-\\,Neural\\,Networks\\,and\\,Learning}$\n",
    "##### $Assignment:\\,\\color{blue}{MSAAI\\,Final\\,Project}$\n",
    "##### $Date:\\,\\color{blue}{8/15/2023}$\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc343580",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13274e2-c25d-4b74-8ebf-4c8c0c18b7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n",
      "GPU Name:  NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "# Libraries \n",
    "\n",
    "# File and Data Handling\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Data Visualization and Numerical Computing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# MIDI Processing\n",
    "import mido\n",
    "\n",
    "# Machine Learning and Deep Learning\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# Machine learning Metrics and Evaluations\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print('GPU Available: ', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU Name: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    device = torch.device(\"cuda:\" + str(torch.cuda.current_device())) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c13ef",
   "metadata": {},
   "source": [
    "### Classes\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2a17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def enum(self,y):\n",
    "        composers = [\"bach\", \"bartok\", \"byrd\", \"chopin\", \"handel\", \"hummel\", \"mendelssohn\",\"mozart\", \"schumann\"]\n",
    "        #print(y)\n",
    "        for i in range(len(composers)):\n",
    "            if composers[i] == y:\n",
    "                slot = i\n",
    "        out = [0] * 9\n",
    "        out[slot] = 1\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        label = self.enum(label)\n",
    "           \n",
    "        \n",
    "        sequence = torch.tensor(sequence)\n",
    "        label = torch.tensor(label)\n",
    "        if torch.cuda.is_available():\n",
    "            label = label.to(device)\n",
    "            #print('GPU Tensor Enabled(Labels):', label.is_cuda)\n",
    "            sequence = sequence.to(device)\n",
    "            #print('GPU Tensor Enabled(Sequences):', sequence.is_cuda)\n",
    "        sequence = sequence[None, :, :] \n",
    "        return sequence, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ffd187",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a13e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(a_dir):\n",
    "    dirs = []\n",
    "    files = []\n",
    "    for name in os.listdir(a_dir):\n",
    "        if os.path.isdir(os.path.join(a_dir, name)):\n",
    "            dirs.append(name)\n",
    "        else:\n",
    "            files.append(name)\n",
    "    return [dirs,files]\n",
    "\n",
    "def create_files_table(top_level, out_file):\n",
    "    temp_comps = []\n",
    "    temp_songs = []\n",
    "    temp_paths = []\n",
    "    \n",
    "    composer_names, songs = get_children(top_level)\n",
    "\n",
    "    for composer in composer_names:\n",
    "        temp_path = top_level + '/' + composer\n",
    "        temp, songs = get_children(temp_path)\n",
    "        for song in songs:\n",
    "            if song != '.DS_Store':\n",
    "                temp_comps.append(composer)\n",
    "                temp_paths.append(temp_path + '/' + song)\n",
    "                temp_songs.append(song.split(\".\")[0])\n",
    "\n",
    "    temp_dict = {'Composers': temp_comps, 'Songs': temp_songs, 'Paths': temp_paths}\n",
    "\n",
    "    table = pd.DataFrame.from_dict(temp_dict)\n",
    "\n",
    "    table.to_csv('./' + out_file + '.csv',index=False)\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n",
    "# Function to extract the notes played in a MIDI file with timestamps\n",
    "def extract_notes_with_meta(midi_filepath):\n",
    "    notes = {}\n",
    "    midi = mido.MidiFile(midi_filepath)\n",
    "    max_time = 0\n",
    "    time_counter = 0\n",
    "    for track in midi.tracks:\n",
    "        time_counter = 0\n",
    "        for msg in track:\n",
    "            time_counter += msg.time\n",
    "            max_time = max(max_time,time_counter)\n",
    "            if msg.type == 'note_on':\n",
    "                if msg.velocity != 0:  # Ensure it's a Note On event\n",
    "                    notes[msg.note] = notes.get(msg.note, []) + [(msg.velocity, time_counter, 1)]  # 1 represents Note On\n",
    "            elif msg.type == 'note_off':\n",
    "                notes[msg.note] = notes.get(msg.note, []) + [(msg.velocity,time_counter, 0)]  # 0 represents Note Off\n",
    "                \n",
    "    return notes, max_time\n",
    "\n",
    "\n",
    "def create_single_sequences(notes, start, tick_count, seq_count): \n",
    "    VEL = 0\n",
    "    TM = 1\n",
    "    ON = 2\n",
    "    \n",
    "    temp_keys = notes.keys()\n",
    "\n",
    "    seq =  [[0] * 128]* seq_count\n",
    "    seq = np.array(seq)\n",
    "\n",
    "    for x in temp_keys:\n",
    "        temp_note = np.array(notes[x])\n",
    "        time_store = 0\n",
    "        for i in range(start, seq_count+start):\n",
    "            temp_vel = 0\n",
    "            for t in range(time_store,temp_note[:,TM].size):\n",
    "                if (temp_note[t,TM]>tick_count*i):\n",
    "                    break\n",
    "                else:\n",
    "                    if temp_note[t,ON] == 1:\n",
    "                        if temp_note[t,VEL] > temp_vel:\n",
    "                            temp_vel = temp_note[t,VEL]\n",
    "                time_store = t\n",
    "            seq[i-start,x] = temp_vel\n",
    "    return seq\n",
    "\n",
    "def sequence_songs(df_songs, tick_count, seq_count, jiggle_on=False):\n",
    "    labels = []\n",
    "    sequences = []\n",
    "    \n",
    "    \n",
    "    shake_amount = [0]\n",
    "    #num_jiggle = 3\n",
    "    \n",
    "    if jiggle_on:\n",
    "       #for i in range(1,num_jiggle):\n",
    "        #shake_amount.append(int(seq_count/num_jiggle)*i)\n",
    "        #shake_amount = [0, seq_count/4, seq_count/2]\n",
    "        shake_amount = [0, int(seq_count/2)]\n",
    "    \n",
    "    for j in shake_amount:\n",
    "        for song in df_songs.iterrows():\n",
    "            temp_count = tick_count\n",
    "            song = song[1]\n",
    "            notes, max_time = extract_notes_with_meta(song['Paths'])\n",
    "            if max_time / tick_count < seq_count:\n",
    "                temp_count = int((max_time / seq_count)*.8)\n",
    "            for i in range(int((max_time-j)/(seq_count*temp_count))):\n",
    "                sequences.append(create_single_sequences(notes, i*seq_count+j, temp_count, seq_count))\n",
    "                labels.append(song['Composers'])\n",
    "                \n",
    "    return labels, sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d0145",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baba92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "devpath = './Composer_Dataset/NN_midi_files_extended/dev/'\n",
    "testpath = './Composer_Dataset/NN_midi_files_extended/test/'\n",
    "trainpath = './Composer_Dataset/NN_midi_files_extended/train/'\n",
    "\n",
    "dev_table = create_files_table(devpath, 'dev_table')\n",
    "test_table = create_files_table(testpath, 'test_table')\n",
    "train_table = create_files_table(trainpath, 'train_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38ea1d3-2dbd-4a8b-befc-2d2ec5edeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_file_path = './Composer_Dataset/NN_midi_files_extended/dev/bach/bach344.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d65289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1labels, sequences = sequence_songs(train_table, 200, 128,jiggle_on=True)\n",
    "# A tick rate of 9999 will end up turning on dynamic sampling based on the length of the song\n",
    "labels, sequences = sequence_songs(train_table, 300, 128,jiggle_on=true)\n",
    "#2labels, sequences = sequence_songs(train_table,  128, 128,jiggle_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0ddc86-088f-4496-bec5-4a18519e781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1labels_test, sequences_test = sequence_songs(test_table, 200, 128,jiggle_on=True)\n",
    "# A tick rate of 9999 will end up turning on dynamic sampling based on the length of the song\n",
    "labels_test, sequences_test = sequence_songs(test_table, 300, 128,jiggle_on=true)\n",
    "#2labels_test, sequences_test = sequence_songs(test_table, 128, 128,jiggle_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3134245-faec-4661-8bb1-bd6be81963bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bach',\n",
       " 'bartok',\n",
       " 'byrd',\n",
       " 'chopin',\n",
       " 'handel',\n",
       " 'hummel',\n",
       " 'mendelssohn',\n",
       " 'mozart',\n",
       " 'schumann'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myset = set(labels_test)\n",
    "myset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2346fe46-e169-42c0-984e-2df368b2ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_notes_with_meta('./Composer_Dataset/NN_midi_files_extended/test/byrd/byrd150.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3d0cc4d-b025-4a19-988f-efaf34735853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bach', 'bartok', 'byrd', 'chopin', 'handel', 'hummel',\n",
       "       'mendelssohn', 'mozart', 'schumann'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dsadasda\n",
    "train_table.Composers.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caac14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset for the dataloader\n",
    "dataset = Dataset(sequences, labels)\n",
    "dataset_test = Dataset(sequences_test, labels_test)\n",
    "\n",
    "# Creating data loader\n",
    "batch_size = 1\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d82b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a82b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df820bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Creation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfd7922c-c399-4931-b7f2-4b598b811bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=2, padding=1)\n",
    "    \n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.LSTM = nn.LSTM(8, 300, 7, batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(2400, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 600)\n",
    "        self.fc3 = nn.Linear(600, 100)\n",
    "        self.fc4 = nn.Linear(100, 9)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv4(x)))\n",
    "\n",
    "        x =  x[:,0,:,:]\n",
    "        h0 = torch.zeros(7, x.size(0), 300)\n",
    "        c0 = torch.zeros(7, x.size(0), 300)     \n",
    "        if torch.cuda.is_available():\n",
    "            h0 = h0.to(device)\n",
    "            #print('GPU Tensor Enabled(labels):', labels.is_cuda)\n",
    "            c0 = c0.to(device)\n",
    "            #print('GPU Tensor Enabled(inputs):', inputs.is_cuda)\n",
    "        x, _ = self.LSTM(x, (h0, c0)) \n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        # return nn.functional.sigmoid(x)\n",
    "        return self.soft(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9374daab-2a1b-46d0-a166-575e60220c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = CNN() \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adagrad(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9deab72f-014a-430f-af2e-26b33e47fb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model-4_something-Best717.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c7c99",
   "metadata": {},
   "source": [
    "### Training\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31834753-2b6a-4307-b02e-b312ff6425a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Test(dataloader, best_model):\n",
    "    # Evaluating the model\n",
    "    model.eval()\n",
    "\n",
    "    real = []\n",
    "    pred = []\n",
    "    counter = 0\n",
    "    # Disable gradient computation to save memory\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            outputs = outputs.tolist()\n",
    "            labels = labels.tolist()\n",
    "\n",
    "            pred_labal = outputs[0].index(max(outputs[0]))\n",
    "\n",
    "            real_label = labels[0].index(max(labels[0]))\n",
    "\n",
    "            real.append(real_label)\n",
    "            pred.append(pred_labal)\n",
    "            \n",
    "    \n",
    "    score = f1_score(pred, real, average = \"weighted\")\n",
    "    \n",
    "    if score > best_model:\n",
    "        print(classification_report(real, pred))\n",
    "        best_model = score\n",
    "        torch.save(model.state_dict(), 'model_something.pt')\n",
    "    \n",
    "    return score, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "825b4f23-3f94-489f-ad5d-4bd7ca43fbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = 0.7175077123970345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b75eec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/180] Loss: 0.0707 Time-Taken: 24.286863327026367s F1-Score: 0.47531603724863325 Best-Score: 0.7175077123970345\n",
      "Epoch [2/180] Loss: 0.0620 Time-Taken: 27.0036883354187s F1-Score: 0.5426699926996553 Best-Score: 0.7175077123970345\n",
      "Epoch [3/180] Loss: 0.0593 Time-Taken: 25.322386503219604s F1-Score: 0.5606323098895507 Best-Score: 0.7175077123970345\n",
      "Epoch [4/180] Loss: 0.0574 Time-Taken: 24.935598134994507s F1-Score: 0.5740809681320934 Best-Score: 0.7175077123970345\n",
      "Epoch [5/180] Loss: 0.0558 Time-Taken: 26.416887760162354s F1-Score: 0.5855875658150573 Best-Score: 0.7175077123970345\n",
      "Epoch [6/180] Loss: 0.0548 Time-Taken: 22.57597804069519s F1-Score: 0.5647704511199881 Best-Score: 0.7175077123970345\n",
      "Epoch [7/180] Loss: 0.0537 Time-Taken: 27.9418625831604s F1-Score: 0.5823888806557918 Best-Score: 0.7175077123970345\n",
      "Epoch [8/180] Loss: 0.0527 Time-Taken: 27.974105834960938s F1-Score: 0.5657158223241805 Best-Score: 0.7175077123970345\n",
      "Epoch [9/180] Loss: 0.0521 Time-Taken: 28.382336139678955s F1-Score: 0.5421359096843461 Best-Score: 0.7175077123970345\n",
      "Epoch [10/180] Loss: 0.0510 Time-Taken: 25.557473182678223s F1-Score: 0.5621150126727671 Best-Score: 0.7175077123970345\n",
      "Epoch [11/180] Loss: 0.0504 Time-Taken: 25.68424367904663s F1-Score: 0.5425845673390118 Best-Score: 0.7175077123970345\n",
      "Epoch [12/180] Loss: 0.0497 Time-Taken: 26.793582439422607s F1-Score: 0.5349195868561616 Best-Score: 0.7175077123970345\n",
      "Epoch [13/180] Loss: 0.0495 Time-Taken: 26.589792728424072s F1-Score: 0.6000544328380394 Best-Score: 0.7175077123970345\n",
      "Epoch [14/180] Loss: 0.0488 Time-Taken: 23.349608659744263s F1-Score: 0.5723758401317822 Best-Score: 0.7175077123970345\n",
      "Epoch [15/180] Loss: 0.0481 Time-Taken: 23.8089861869812s F1-Score: 0.5496278324752782 Best-Score: 0.7175077123970345\n",
      "Epoch [16/180] Loss: 0.0473 Time-Taken: 28.465497493743896s F1-Score: 0.5700284706345117 Best-Score: 0.7175077123970345\n",
      "Epoch [17/180] Loss: 0.0471 Time-Taken: 24.606595993041992s F1-Score: 0.5615768847132384 Best-Score: 0.7175077123970345\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 24\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Print the average loss for the epoch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\optim\\adagrad.py:153\u001b[0m, in \u001b[0;36mAdagrad.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    150\u001b[0m             state_sums\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    151\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 153\u001b[0m     \u001b[43madagrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_sums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\optim\\adagrad.py:208\u001b[0m, in \u001b[0;36madagrad\u001b[1;34m(params, grads, state_sums, state_steps, has_sparse_grad, foreach, lr, weight_decay, lr_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adagrad\n\u001b[1;32m--> 208\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_sums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\optim\\adagrad.py:278\u001b[0m, in \u001b[0;36m_single_tensor_adagrad\u001b[1;34m(params, grads, state_sums, state_steps, lr, weight_decay, lr_decay, eps, has_sparse_grad, maximize)\u001b[0m\n\u001b[0;32m    276\u001b[0m state_sum\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    277\u001b[0m std \u001b[38;5;241m=\u001b[39m state_sum\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m--> 278\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mclr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_complex:\n\u001b[0;32m    280\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_complex(param)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 180\n",
    "prev = time.time()\n",
    "cur_model = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in data_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(torch.float)\n",
    "        labels = labels.to(torch.float)\n",
    "        if torch.cuda.is_available():\n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    cur_model, best_model = Test(test_loader, best_model)\n",
    "    now = time.time()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} Time-Taken: {now-prev}s F1-Score: {cur_model} Best-Score: {best_model}\")\n",
    "    prev = now\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc2f9a",
   "metadata": {},
   "source": [
    "### Evaulation and Results\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa6afa7-b366-4a38-815f-f752c2ba074a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "\n",
    "prediction_list = list()\n",
    "labels_list = list()\n",
    "\n",
    "real = []\n",
    "pred = []\n",
    "counter = 0\n",
    "# Disable gradient computation to save memory\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        #print(outputs)\n",
    "        \n",
    "        outputs = outputs.tolist()\n",
    "        labels = labels.tolist()\n",
    "        \n",
    "        pred_labal = outputs[0].index(max(outputs[0]))\n",
    "        \n",
    "\n",
    "        #print(pred_labal)\n",
    "        \n",
    "        #print(labels)\n",
    "        \n",
    "        real_label = labels[0].index(max(labels[0]))\n",
    "        \n",
    "        real.append(real_label)\n",
    "        pred.append(pred_labal)\n",
    "\n",
    "\n",
    "        \n",
    "print(classification_report(real, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc25cb-3c23-41e6-bb6b-5beb134effee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = [0]\n",
    "length = 256\n",
    "\n",
    "for i in range(1,8):\n",
    "    temp.append(int(length/8)*i)\n",
    "    \n",
    "print(temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a18feb-57ea-4c53-a7e2-fdfd576ad4ad",
   "metadata": {},
   "source": [
    "pred = []\n",
    "\n",
    "for inputs, labels in data_loader:\n",
    "    inputs = inputs.to(torch.float)\n",
    "    labels = labels.to(torch.float)\n",
    "    \n",
    "\n",
    "    pred.append(model(inputs).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
